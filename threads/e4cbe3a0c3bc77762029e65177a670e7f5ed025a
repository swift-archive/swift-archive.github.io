<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Swift Mailing List Archive</title>
    <link rel="stylesheet" href="/css/app-13f065ae5e595562a5022c544e3b976c.css">
  </head>

  <body>
    <div class="container">
      <header class="header">
        <img src="/images/swift-d0237fc716ba0932a940049990beba1b.svg" height="70">
      </header>

      <p class="alert alert-info" role="alert"></p>
      <p class="alert alert-danger" role="alert"></p>

    </div> <!-- /container -->
    <main role="main">
<div class="comment-wrapper"><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/d53b7c5f9b5f5557b9082face9b632a0?s=50"></div><header><strong>[RFC] New collections model: collections advance indices</strong> from <string>Dave Abrahams</string> &lt;dabrahams at apple.com&gt;<p>March  4, 2016 at 06:00:00am</p></header><div class="content"><p>on Thu Mar 03 2016, Károly Lőrentey &lt;swift-evolution at swift.org&gt; wrote:<br></p><p>&gt; On 2016-03-03 16:25:45 +0000, Dave Abrahams via swift-evolution said:<br>&gt;&gt;<br>&gt;&gt; on Tue Mar 01 2016, Károly Lőrentey &lt;swift-evolution at swift.org&gt; wrote:<br>&gt;&gt;<br>&gt;&gt;&gt; This looks interesting! As the author of a number of custom collection<br>&gt;&gt;&gt; implementations, including a rather elaborate B-tree package<br>&gt;&gt;&gt; (https://github.com/lorentey/BTree),<br>&gt;&gt;<br>&gt;&gt; FWIW, I am impressed by (even jealous of) this work, so your feedback in<br>&gt;&gt; this area is much appreciated.<br>&gt;<br>&gt; Why thank you. *blush*<br>&gt;<br>&gt;&gt; One thing that hasn&#39;t been mentioned so far is that when the algorithms<br>&gt;&gt; using indices are extensions on the collection protocol (or members of a<br>&gt;&gt; specific collection) these APIs can be used without qualification, which<br>&gt;&gt; makes them read like free functions, which ends up looking quite natural<br>&gt;&gt; to my eye.<br>&gt;<br>&gt; Nice!<br>&gt;<br>&gt;&gt;&gt; - I know that it isn&#39;t a new requirement, but I do dislike that<br>&gt;&gt;&gt; `Indexable` specifies the complexity of index operations; this puts<br>&gt;&gt;&gt; a hard constraint on custom collection design. I do understand the<br>&gt;&gt;&gt; desire for concrete complexity promises on operations using<br>&gt;&gt;&gt; indexes, but can&#39;t we express these instead e.g. in terms of number<br>&gt;&gt;&gt; of index accesses?<br>&gt;&gt;<br>&gt;&gt; The problem is that eventually it becomes really difficult to simply<br>&gt;&gt; describe the efficiency of any given algorithm.  We don&#39;t want people to<br>&gt;&gt; have to do complex algebra to understand how algorithms compose with<br>&gt;&gt; data structures.<br>&gt;&gt;<br>&gt;&gt; Yes, it&#39;s a trade-off, and loosening the upper bound on the cost of<br>&gt;&gt; indexing was one of the things we considered.  We tried to carefully<br>&gt;&gt; think through different possible collection designs (trees in<br>&gt;&gt; particular!) to understand what the implications of keeping the O(1)<br>&gt;&gt; upper bound were.  We&#39;d be happy to discuss specific tradeoffs with you.<br>&gt;<br>&gt; That&#39;s fair! So far, I&#39;ve always been able to implement constant access,<br>&gt; and the code has only become better of it.<br>&gt;<br>&gt; The only place where I intentionally decided against it is the tree-backed,<br>&gt; Array-like `List`. It really wants to be indexed by an Int, to emulate<br>&gt; Array&#39;s loose approach to index invalidation. (Although, like you said,<br>&gt; B-tree lookup is practically O(1) anyway, so maybe I&#39;ll just call it that.)<br>&gt;<br>&gt; This reminds me that index invalidation rules are all over the place across<br>&gt; the various collection types and not very well documented. Some ideas for<br>&gt; improvements:<br>&gt;<br>&gt; - From the sample code in its documentation, it looks like<br>&gt;  `MutableCollection` requires subscript assignment to not invalidate<br>&gt;  indices. Can we make this a formal requirement?<br></p><p>IMO yes, we should; IIRC it&#39;s intended to be one.  Part of Dmitri&#39;s<br>project has been to develop an understanding of what indices are<br>supposed to be, conceptually.  We settled on “a path to a node in the<br>data structure,” which allows us to say with confidence that subscript<br>assignment doesn&#39;t invalidate any indices.  Making this guarantee does<br>have some side-effects, e.g., that when assigning through a subscript of<br>a COW value-type data structure with a non-unique reference, you may not<br>be able to rebalance or compress away unused storage in the new unique<br>copy.<br></p><p>&gt; - What about range assignment in `MutableCollection`? E.g., what<br>&gt; happens to indices if it changes the element count? <br></p><p>I think that&#39;s unspecified and in the general case that means indices<br>are invalidated.<br></p><p>&gt; (Is supporting that a requirement?)<br></p><p>Yes, IIRC supporting that is a requirement; it&#39;s sort of implied by<br>being able to do in-place mutation like c[a..&lt;b].sort().<br></p><p>&gt; - Does `RangeReplacableCollection` imply Array-like index<br>&gt; invalidation?  I think it should.<br></p><p>“Array-like” is too vague for me to answer that question.  Certainly<br>array will give some invalidation guarantees that are not always<br>available from `RangeReplacableCollection`s in general.<br></p><p>&gt; By the way, does the requirement for (amortized) constant complexity also<br>&gt; apply to advancing an index? That&#39;s OK for trees, but it may not come cheap<br>&gt; for hashed collections. <br></p><p>I think you have to handle this by ensuring some minimum load factor.<br>As a result, deletions must be allowed to invalidate indices of elements<br>that aren&#39;t being deleted, which is, after all, true of Array.<br></p><p>&gt; Native dictionaries &amp; sets currently have an index.successor() with<br>&gt; O(n) complexity (if I&#39;m not mistaken).<br></p><p>Yes, ensuring minimum load factor is something we haven&#39;t gotten around<br>to yet.<br></p><p>&gt; What about `Collection.indices`? Getting the first index will definitely<br>&gt; take O(log(n)) for tree collections, <br></p><p>Not if you store that index in the root of the tree.<br></p><p>&gt; and bridged dictionaries/sets have this at O(n).<br></p><p>Bridging throws all efficiency guarantees out the window anyway, since<br>anybody is allowed to subclass any of those Foundation classes and give<br>it arbitrarily bad performance.<br></p><p>&gt;&gt;&gt; - I&#39;m using weak references inside the index, with a (seriously<br>&gt;&gt;&gt; underdeveloped) index invalidation method that happens to be closer<br>&gt;&gt;&gt; to #2b than #2a. I&#39;m not happy about using weak references, but this<br>&gt;&gt;&gt; seemed the most sensible thing to do. I&#39;d love to replace them with<br>&gt;&gt;&gt; `unowned(unsafe)`, and the mutation counter seems like a great idea.<br>&gt;&gt;&gt; The ARC issue mentioned at the end of the proposal is rather scary,<br>&gt;&gt;&gt; though -- I don&#39;t know how I would protect against that.<br>&gt;&gt;<br>&gt;&gt; Hmm, Dmitri, I thought we decided that using unowned(unsafe) to manage<br>&gt;&gt; the &quot;indices&quot; collection was simply untenable.  Remember the<br>&gt;&gt; thread-safety issue, iterating indices on one thread while mutating the<br>&gt;&gt; collection on another?<br>&gt;<br>&gt; Hm, aren&#39;t multithreaded mutations supposed to use COW to get their own<br>&gt; copy to mutate?<br></p><p>Yes, but if you use unowned(unsafe), you don&#39;t allow the evaluation of<br>`x.indices` to bump the reference count, and you thereby defeat this<br>mechanism.  That&#39;s my point.<br></p><p>&gt; Or is this about invalidation of the return value of<br>&gt; `Collection.indices`?<br></p><p>That&#39;s one way to look at it.<br></p><p>&gt; <br>&gt; That&#39;s not supposed to survive (all) mutations, is it?<br></p><p>It is.<br></p><p>&gt; (Ugh, how do I refer to an instance of Indices (the associated type) without<br>&gt; confusing it with indices in the sense of multiple `Index`es?)<br></p><p>“an instance of Indices” works fine.  You can also use `x.indices`.<br></p><p>&gt;&gt;&gt; - I&#39;m almost positive this has been discussed before, but what is the<br>&gt;&gt;&gt; rationale behind allowing non-Int `IndexDistance`s?<br>&gt;&gt;<br>&gt;&gt; One could imagine indexing a file-backed thing on a 32-bit platform,<br>&gt;&gt; which could require 64-bit distances.<br>&gt;<br>&gt; Ah, OK! But it begs the question: would a file-backed collection be able<br>&gt; to satisfy the O(1) indexing requirement without making a complete<br>&gt; mockery of it? :-)<br></p><p>Sure; it has a large constant factor, but we do expect disk access times<br>to be bounded by a constant.<br></p><p>&gt;&gt;&gt; The distance is getting cast to Int in a lot of places anyway (IIRC,<br>&gt;&gt;&gt; even the stdlib uses numericCasts to cut a way through it.)<br>&gt;&gt;<br>&gt;&gt; We&#39;ve tried to be careful enough in balancing ease-of-use (Int<br>&gt;&gt; almost everywhere) with flexibility, but we might have made mistakes,<br>&gt;&gt; for sure.<br>&gt;<br>&gt; I think the largest speed bump there is that sequences and collections<br>&gt; are often loaded into Arrays, and an oversized collection would have to<br>&gt; tread very carefully to avoid all of these places. <br></p><p>Sequences much more so than collections: this happens when we need to<br>create multi-pass-ness from thin air.<br></p><p>&gt; The API is geared towards finite (and relatively small-ish)<br>&gt; collections/sequences.  I suspect a Collection with a billion elements<br>&gt; wouldn&#39;t work much better than an infinite sequence.<br></p><p>I don&#39;t know why you say so.  I could easily imagine doing a binary<br>search in such a thing, for example.<br></p><p>&gt;&gt;&gt; - In this declaration:<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; subscript(position: Index) -&gt; Generator.Element { get }<br>&gt;&gt;&gt;<br>&gt;&gt;&gt; I find the argument name rather unfortunate, because I&#39;ve been using<br>&gt;&gt;&gt; the term &quot;position&quot; to consistently refer to the (numerical)<br>&gt;&gt;&gt; position of an element in an ordered collection,<br>&gt;&gt;<br>&gt;&gt; “Offset” would be a better name for that, IMO.<br>&gt;<br>&gt; That&#39;s spot on! Although in some contexts it could be misunderstood to<br>&gt; mean a delta. I&#39;ll sleep on it, but I think you&#39;re right.<br></p><p>I think “numerical position” wouldn&#39;t hurt your prose much, and if it<br>does you&#39;re probably overly-reliant on that concept where “position”<br>would do fine.  But I haven&#39;t seen your text, so I&#39;m really just<br>speculating.<br></p><p>-- <br>-Dave<br></p></div></li></ul></div>    </main>
    <script src="/js/app-c283ee129de63ad743722e9511e67a5d.js"></script>
  </body>
  <footer>
    <p>Swift and the Swift logo are trademarks of Apple Inc.</p>
  </footer>
</html>
