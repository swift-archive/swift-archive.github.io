<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Swift Mailing List Archive</title>
    <link rel="stylesheet" href="/css/app-13f065ae5e595562a5022c544e3b976c.css?vsn=d">
  </head>

  <body>
    <div class="container">
      <header class="header">
        <img src="/images/swift-d0237fc716ba0932a940049990beba1b.svg?vsn=d" height="70">
      </header>

      <p class="alert alert-info" role="alert"></p>
      <p class="alert alert-danger" role="alert"></p>

    </div> <!-- /container -->
    <main role="main">
<div class="comment-wrapper"><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/ccbc60826cca6a6f9c527b671cdad531?s=50"></div><header><strong>StringLiteralConvertible protocol question</strong> from <string>Loïc Lecrenier</string> &lt;loiclecrenier at icloud.com&gt;<p>January 10, 2016 at 09:00:00pm</p></header><div class="content"><p>Hi :)<br></p><p>I have been trying to understand the StringLiteralConvertible protocol, but there is something that I still can’t explain.<br></p><p>//-----------------------------<br></p><p>extension Int : UnicodeScalarLiteralConvertible {<br>    public init(unicodeScalarLiteral value: UnicodeScalar) {<br>        self = 1<br>    }<br>}<br></p><p>extension Int : ExtendedGraphemeClusterLiteralConvertible {<br>    public init(extendedGraphemeClusterLiteral value: Character) {<br>        self = 2<br>    }<br>}<br></p><p>extension Int : StringLiteralConvertible {<br>    public init(stringLiteral value: String) {<br>        self = 3<br>    }<br>}<br></p><p>let a : Int = &quot;\u{65}&quot; // e<br>let b : Int = &quot;\u{65}\u{0301}&quot; // é<br>let c : Int = “hello&quot;<br></p><p>//-----------------------------<br></p><p>If I only write the first extension: I can only initialize a, and its value will be 1.<br>If I write the first two extensions: I can initialize a and b, and their values will be 2. <br>And if I keep the three extensions: a, b, and c will all have a value of 3.<br></p><p>So it seems like the compiler prefers calling the initializer from (in order of preference):<br>1. StringLiteralConvertible<br>2. ExtendedGraphemeClusterLiteralConvertible<br>3. UnicodeScalarLiteralConvertible<br></p><p>But for something to be StringLiteralConvertible, it needs to be ExtendedGraphemeClusterLiteralConvertible and UnicodeScalarLiteralConvertible, which means I have to define two initializers that will never be called.<br></p><p>Is that correct?<br>Is there a way to write something that is a unicode scalar literal, but not a string literal?<br></p><p>Thank you, <br></p><p>Loïc<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/957b675456a66c394945a7361aedd51d?s=50"></div><header><strong>StringLiteralConvertible protocol question</strong> from <string>Zhao Xin</string> &lt;owenzx at gmail.com&gt;<p>January 11, 2016 at 12:00:00pm</p></header><div class="content"><p>&gt;<br>&gt; But for something to be StringLiteralConvertible, it needs to be<br>&gt; ExtendedGraphemeClusterLiteralConvertible and<br>&gt; UnicodeScalarLiteralConvertible, which means I have to define two<br>&gt; initializers that will never be called.<br></p><p><br>Yes. Because<br>​StringLiteralConvertible inherits<br>from ExtendedGraphemeClusterLiteralConvertible,<br>ExtendedGraphemeClusterLiteralConvertible<br>inherits from<br>UnicodeScalarLiteralConvertible.<br>​<br></p><p>Is there a way to write something that is a unicode scalar literal, but not<br>&gt; a string literal?<br></p><p>​Yes. You have already done it by ​extension UnicodeScalarLiteralConvertible<br>only. String literal is what people read. Unicode is something string<br>encoding to store in computer and the computer read.<br></p><p>for example:<br></p><p>let uScalar = &quot;a&quot;.unicodeScalars.first! // 97<br>print(uScalar.dynamicType) // UnicodeScalar. NOT an Int<br></p><p><br>On Mon, Jan 11, 2016 at 4:54 AM, Loïc Lecrenier &lt;swift-users at swift.org&gt;<br>wrote:<br></p><p>&gt; Hi :)<br>&gt;<br>&gt; I have been trying to understand the StringLiteralConvertible protocol,<br>&gt; but there is something that I still can’t explain.<br>&gt;<br>&gt; //-----------------------------<br>&gt;<br>&gt; extension Int : UnicodeScalarLiteralConvertible {<br>&gt;     public init(unicodeScalarLiteral value: UnicodeScalar) {<br>&gt;         self = 1<br>&gt;     }<br>&gt; }<br>&gt;<br>&gt; extension Int : ExtendedGraphemeClusterLiteralConvertible {<br>&gt;     public init(extendedGraphemeClusterLiteral value: Character) {<br>&gt;         self = 2<br>&gt;     }<br>&gt; }<br>&gt;<br>&gt; extension Int : StringLiteralConvertible {<br>&gt;     public init(stringLiteral value: String) {<br>&gt;         self = 3<br>&gt;     }<br>&gt; }<br>&gt;<br>&gt; let a : Int = &quot;\u{65}&quot; // e<br>&gt; let b : Int = &quot;\u{65}\u{0301}&quot; // é<br>&gt; let c : Int = “hello&quot;<br>&gt;<br>&gt; //-----------------------------<br>&gt;<br>&gt; If I only write the first extension: I can only initialize a, and its<br>&gt; value will be 1.<br>&gt; If I write the first two extensions: I can initialize a and b, and their<br>&gt; values will be 2.<br>&gt; And if I keep the three extensions: a, b, and c will all have a value of 3.<br>&gt;<br>&gt; So it seems like the compiler prefers calling the initializer from (in<br>&gt; order of preference):<br>&gt; 1. StringLiteralConvertible<br>&gt; 2. ExtendedGraphemeClusterLiteralConvertible<br>&gt; 3. UnicodeScalarLiteralConvertible<br>&gt;<br>&gt; But for something to be StringLiteralConvertible, it needs to be<br>&gt; ExtendedGraphemeClusterLiteralConvertible and<br>&gt; UnicodeScalarLiteralConvertible, which means I have to define two<br>&gt; initializers that will never be called.<br>&gt;<br>&gt; Is that correct?<br>&gt; Is there a way to write something that is a unicode scalar literal, but<br>&gt; not a string literal?<br>&gt;<br>&gt; Thank you,<br>&gt;<br>&gt; Loïc<br>&gt;<br>&gt;<br>&gt;<br>&gt;<br>&gt;<br>&gt;<br>&gt; _______________________________________________<br>&gt; swift-users mailing list<br>&gt; swift-users at swift.org<br>&gt; https://lists.swift.org/mailman/listinfo/swift-users<br>&gt;<br></p><p><br></p><p>-- <br></p><p>Owen Zhao<br>-------------- next part --------------<br>An HTML attachment was scrubbed...<br>URL: &lt;https://lists.swift.org/pipermail/swift-users/attachments/20160111/7da77124/attachment.html&gt;<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/ccbc60826cca6a6f9c527b671cdad531?s=50"></div><header><strong>StringLiteralConvertible protocol question</strong> from <string>Loïc Lecrenier</string> &lt;loiclecrenier at icloud.com&gt;<p>January 11, 2016 at 03:00:00pm</p></header><div class="content"><p>&gt; Yes. Because ​StringLiteralConvertible inherits from ExtendedGraphemeClusterLiteralConvertible, ExtendedGraphemeClusterLiteralConvertible inherits from UnicodeScalarLiteralConvertible.​<br></p><p>Yes, I know. But I wonder why that is, considering that something that is StringLiteralConvertible will seemingly never use the required initializer from UnicodeScalarLiteralConvertible.<br></p><p>&gt; Is there a way to write something that is a unicode scalar literal, but not a string literal?<br>&gt; ​Yes. You have already done it by ​extension UnicodeScalarLiteralConvertible only. String literal is what people read. Unicode is something string encoding to store in computer and the computer read.<br>&gt; <br>&gt; for example:<br>&gt; <br>&gt; let uScalar = &quot;a&quot;.unicodeScalars.first! // 97<br>&gt; print(uScalar.dynamicType) // UnicodeScalar. NOT an Int<br></p><p>Sorry, I am not sure what this answers :(<br></p><p>I wanted to know if there was a way to write something like (for example) uscalar”\u{65}”, that would only be a unicode scalar literal, and not a string literal. Or if there was any other way to tell the compiler “please use the initializer from UnicodeScalarLiteralConvertible instead of the one from StringLiteralConvertible”.<br></p><p>I guess the more fundamental question I wanted to ask was “why must StringLiteralConvertible conform to UnicodeScalarLiteralConvertible?”<br></p><p>Thanks,<br>Loïc<br></p><p>&gt; <br>&gt; On Mon, Jan 11, 2016 at 4:54 AM, Loïc Lecrenier &lt;swift-users at swift.org&gt; wrote:<br>&gt; Hi :)<br>&gt; <br>&gt; I have been trying to understand the StringLiteralConvertible protocol, but there is something that I still can’t explain.<br>&gt; <br>&gt; //-----------------------------<br>&gt; <br>&gt; extension Int : UnicodeScalarLiteralConvertible {<br>&gt;     public init(unicodeScalarLiteral value: UnicodeScalar) {<br>&gt;         self = 1<br>&gt;     }<br>&gt; }<br>&gt; <br>&gt; extension Int : ExtendedGraphemeClusterLiteralConvertible {<br>&gt;     public init(extendedGraphemeClusterLiteral value: Character) {<br>&gt;         self = 2<br>&gt;     }<br>&gt; }<br>&gt; <br>&gt; extension Int : StringLiteralConvertible {<br>&gt;     public init(stringLiteral value: String) {<br>&gt;         self = 3<br>&gt;     }<br>&gt; }<br>&gt; <br>&gt; let a : Int = &quot;\u{65}&quot; // e<br>&gt; let b : Int = &quot;\u{65}\u{0301}&quot; // é<br>&gt; let c : Int = “hello&quot;<br>&gt; <br>&gt; //-----------------------------<br>&gt; <br>&gt; If I only write the first extension: I can only initialize a, and its value will be 1.<br>&gt; If I write the first two extensions: I can initialize a and b, and their values will be 2.<br>&gt; And if I keep the three extensions: a, b, and c will all have a value of 3.<br>&gt; <br>&gt; So it seems like the compiler prefers calling the initializer from (in order of preference):<br>&gt; 1. StringLiteralConvertible<br>&gt; 2. ExtendedGraphemeClusterLiteralConvertible<br>&gt; 3. UnicodeScalarLiteralConvertible<br>&gt; <br>&gt; But for something to be StringLiteralConvertible, it needs to be ExtendedGraphemeClusterLiteralConvertible and UnicodeScalarLiteralConvertible, which means I have to define two initializers that will never be called.<br>&gt; <br>&gt; Is that correct?<br>&gt; Is there a way to write something that is a unicode scalar literal, but not a string literal?<br>&gt; <br>&gt; Thank you,<br>&gt; <br>&gt; Loïc<br>&gt; <br>&gt; <br>&gt; <br>&gt; <br>&gt; <br>&gt; <br>&gt; _______________________________________________<br>&gt; swift-users mailing list<br>&gt; swift-users at swift.org<br>&gt; https://lists.swift.org/mailman/listinfo/swift-users<br>&gt; <br>&gt; <br>&gt; <br>&gt; -- <br>&gt; <br>&gt; Owen Zhao<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/957b675456a66c394945a7361aedd51d?s=50"></div><header><strong>StringLiteralConvertible protocol question</strong> from <string>Zhao Xin</string> &lt;owenzx at gmail.com&gt;<p>January 12, 2016 at 09:00:00am</p></header><div class="content"><p>&gt;<br>&gt; &gt; Yes. Because ​StringLiteralConvertible inherits from<br>&gt; ExtendedGraphemeClusterLiteralConvertible,<br>&gt; ExtendedGraphemeClusterLiteralConvertible inherits from<br>&gt; UnicodeScalarLiteralConvertible.​<br>&gt;<br>&gt; Yes, I know. But I wonder why that is, considering that something that is<br>&gt; StringLiteralConvertible will seemingly never use the required initializer<br>&gt; from UnicodeScalarLiteralConvertible.<br></p><p><br>I don&#39;t know it<br>​either. Maybe it is because when you convert a String to Unicode, you will<br>need the other two init()s. As you examples show, there maybe one or two<br>Ints to make one Character.<br></p><p><br>let a : Int = &quot;\u{65}&quot; // e<br>&gt;<br>&gt; let b : Int = &quot;\u{65}\u{0301}&quot; // é<br>&gt;<br>&gt; let c : Int = “hello&quot;<br>&gt;<br>&gt;<br>&gt;<br>I wanted to know if there was a way to write something like (for example)<br>&gt; uscalar”\u{65}”, that would only be a unicode scalar literal, and not a<br>&gt; string literal. Or if there was any other way to tell the compiler “please<br>&gt; use the initializer from UnicodeScalarLiteralConvertible instead of the<br>&gt; one from StringLiteralConvertible”.<br></p><p><br>I guess the more fundamental question I wanted to ask was “why must<br>&gt; StringLiteralConvertible conform to UnicodeScalarLiteralConvertible?”​<br></p><p><br>​For &quot;\u{65}&quot; , in your words, you call it a Unicode Scalar Literal. But in<br>formal, it is a String Literal that include special characters.<br></p><p>String literals can include the following special characters:<br>&gt;<br>&gt;    -<br>&gt;<br>&gt;    The escaped special characters \0 (null character), \\ (backslash), \t (horizontal<br>&gt;    tab), \n (line feed), \r(carriage return), \&quot; (double quote) and \&#39; (single<br>&gt;    quote)<br>&gt;    -<br>&gt;<br>&gt;    An arbitrary Unicode scalar, written as \u{*n*}, where *n* is a 1–8<br>&gt;    digit hexadecimal number with a value equal to a valid Unicode code point<br>&gt;<br>&gt;<br>​If you want to use a UnicodeScalar, you should use struct UnicodeScalar<br>&lt;https://developer.apple.com/library/prerelease/ios/documentation/Swift/Reference/Swift_UnicodeScalar_Structure/&gt;​.<br>Here are the examples.<br></p><p>let uScalar = &quot;a&quot;.unicodeScalars.first! // 97<br>print(uScalar.dynamicType) // UnicodeScalar, not an Int<br></p><p>extension UInt32 {<br>    func hex() -&gt; String {<br>        return String(format:&quot;0x%2X&quot;, self)<br>    }<br>}<br></p><p>var aUnicodeScalar = UnicodeScalar(97)<br>print(aUnicodeScalar.value) //97<br></p><p>aUnicodeScalar = UnicodeScalar(0x61)<br>print(aUnicodeScalar.value) //97<br>print(aUnicodeScalar.value.hex()) //0x61<br></p><p>aUnicodeScalar = UnicodeScalar(&quot;a&quot;)<br>print(aUnicodeScalar.value) //97<br></p><p>aUnicodeScalar = UnicodeScalar(&quot;e&quot;)<br>print(aUnicodeScalar.value.hex()) // 0x65<br></p><p>aUnicodeScalar = UnicodeScalar(&quot;é&quot;)<br>print(aUnicodeScalar.value.hex()) // 0xE9<br></p><p>aUnicodeScalar = UnicodeScalar(&quot;\u{65}&quot;)<br>print(aUnicodeScalar.value.hex()) // 0x65<br></p><p>// aUnicodeScalar = UnicodeScalar(&quot;\u{65}\u{0301}&quot;)<br>// above doesn&#39;t work as there are two characters instead of one<br>// struct UnicodeScalar only conforms UnicodeScalarLiteralConvertible<br></p><p>extension UnicodeScalar:ExtendedGraphemeClusterLiteralConvertible {<br>    public init(extendedGraphemeClusterLiteral value: String) {<br>        self = String(value.characters.first!).unicodeScalars.first!<br>    }<br>}<br></p><p>aUnicodeScalar = UnicodeScalar(extendedGraphemeClusterLiteral:<br>&quot;\u{65}\u{0301}&quot;)<br>print(aUnicodeScalar.value.hex()) // 0x65<br></p><p>zhaoxin<br></p><p>On Mon, Jan 11, 2016 at 10:08 PM, Loïc Lecrenier &lt;loiclecrenier at icloud.com&gt;<br>wrote:<br></p><p>&gt; &gt; Yes. Because ​StringLiteralConvertible inherits from<br>&gt; ExtendedGraphemeClusterLiteralConvertible,<br>&gt; ExtendedGraphemeClusterLiteralConvertible inherits from<br>&gt; UnicodeScalarLiteralConvertible.​<br>&gt;<br>&gt; Yes, I know. But I wonder why that is, considering that something that is<br>&gt; StringLiteralConvertible will seemingly never use the required initializer<br>&gt; from UnicodeScalarLiteralConvertible.<br>&gt;<br>&gt; &gt; Is there a way to write something that is a unicode scalar literal, but<br>&gt; not a string literal?<br>&gt; &gt; ​Yes. You have already done it by ​extension<br>&gt; UnicodeScalarLiteralConvertible only. String literal is what people read.<br>&gt; Unicode is something string encoding to store in computer and the computer<br>&gt; read.<br>&gt; &gt;<br>&gt; &gt; for example:<br>&gt; &gt;<br>&gt; &gt; let uScalar = &quot;a&quot;.unicodeScalars.first! // 97<br>&gt; &gt; print(uScalar.dynamicType) // UnicodeScalar. NOT an Int<br>&gt;<br>&gt; Sorry, I am not sure what this answers :(<br>&gt;<br>&gt; I wanted to know if there was a way to write something like (for example)<br>&gt; uscalar”\u{65}”, that would only be a unicode scalar literal, and not a<br>&gt; string literal. Or if there was any other way to tell the compiler “please<br>&gt; use the initializer from UnicodeScalarLiteralConvertible instead of the one<br>&gt; from StringLiteralConvertible”.<br>&gt;<br>&gt; I guess the more fundamental question I wanted to ask was “why must<br>&gt; StringLiteralConvertible conform to UnicodeScalarLiteralConvertible?”<br>&gt;<br>&gt; Thanks,<br>&gt; Loïc<br>&gt;<br>&gt; &gt;<br>&gt; &gt; On Mon, Jan 11, 2016 at 4:54 AM, Loïc Lecrenier &lt;swift-users at swift.org&gt;<br>&gt; wrote:<br>&gt; &gt; Hi :)<br>&gt; &gt;<br>&gt; &gt; I have been trying to understand the StringLiteralConvertible protocol,<br>&gt; but there is something that I still can’t explain.<br>&gt; &gt;<br>&gt; &gt; //-----------------------------<br>&gt; &gt;<br>&gt; &gt; extension Int : UnicodeScalarLiteralConvertible {<br>&gt; &gt;     public init(unicodeScalarLiteral value: UnicodeScalar) {<br>&gt; &gt;         self = 1<br>&gt; &gt;     }<br>&gt; &gt; }<br>&gt; &gt;<br>&gt; &gt; extension Int : ExtendedGraphemeClusterLiteralConvertible {<br>&gt; &gt;     public init(extendedGraphemeClusterLiteral value: Character) {<br>&gt; &gt;         self = 2<br>&gt; &gt;     }<br>&gt; &gt; }<br>&gt; &gt;<br>&gt; &gt; extension Int : StringLiteralConvertible {<br>&gt; &gt;     public init(stringLiteral value: String) {<br>&gt; &gt;         self = 3<br>&gt; &gt;     }<br>&gt; &gt; }<br>&gt; &gt;<br>&gt; &gt; let a : Int = &quot;\u{65}&quot; // e<br>&gt; &gt; let b : Int = &quot;\u{65}\u{0301}&quot; // é<br>&gt; &gt; let c : Int = “hello&quot;<br>&gt; &gt;<br>&gt; &gt; //-----------------------------<br>&gt; &gt;<br>&gt; &gt; If I only write the first extension: I can only initialize a, and its<br>&gt; value will be 1.<br>&gt; &gt; If I write the first two extensions: I can initialize a and b, and their<br>&gt; values will be 2.<br>&gt; &gt; And if I keep the three extensions: a, b, and c will all have a value of<br>&gt; 3.<br>&gt; &gt;<br>&gt; &gt; So it seems like the compiler prefers calling the initializer from (in<br>&gt; order of preference):<br>&gt; &gt; 1. StringLiteralConvertible<br>&gt; &gt; 2. ExtendedGraphemeClusterLiteralConvertible<br>&gt; &gt; 3. UnicodeScalarLiteralConvertible<br>&gt; &gt;<br>&gt; &gt; But for something to be StringLiteralConvertible, it needs to be<br>&gt; ExtendedGraphemeClusterLiteralConvertible and<br>&gt; UnicodeScalarLiteralConvertible, which means I have to define two<br>&gt; initializers that will never be called.<br>&gt; &gt;<br>&gt; &gt; Is that correct?<br>&gt; &gt; Is there a way to write something that is a unicode scalar literal, but<br>&gt; not a string literal?<br>&gt; &gt;<br>&gt; &gt; Thank you,<br>&gt; &gt;<br>&gt; &gt; Loïc<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt; _______________________________________________<br>&gt; &gt; swift-users mailing list<br>&gt; &gt; swift-users at swift.org<br>&gt; &gt; https://lists.swift.org/mailman/listinfo/swift-users<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt;<br>&gt; &gt; --<br>&gt; &gt;<br>&gt; &gt; Owen Zhao<br>&gt;<br>&gt;<br></p><p><br>-- <br></p><p>Owen Zhao<br>-------------- next part --------------<br>An HTML attachment was scrubbed...<br>URL: &lt;https://lists.swift.org/pipermail/swift-users/attachments/20160112/bcdd3cda/attachment.html&gt;<br></p></div></li></ul></li></ul></li></ul></li></ul></div>    </main>
    <script src="/js/app-c283ee129de63ad743722e9511e67a5d.js?vsn=d"></script>
  </body>
  <footer>
    <p>Swift and the Swift logo are trademarks of Apple Inc.</p>
  </footer>
</html>
