<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Swift Mailing List Archive</title>
    <link rel="stylesheet" href="/css/app-13f065ae5e595562a5022c544e3b976c.css">
  </head>

  <body>
    <div class="container">
      <header class="header">
        <img src="/images/swift-d0237fc716ba0932a940049990beba1b.svg" height="70">
      </header>

      <p class="alert alert-info" role="alert"></p>
      <p class="alert alert-danger" role="alert"></p>

    </div> <!-- /container -->
    <main role="main">
<div class="comment-wrapper"><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/8daa9d0c5cf56d891ee1e33571342032?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Joakim Hassila</string> &lt;Joakim.Hassila at orc-group.com&gt;<p>December  7, 2015 at 12:00:00pm</p></header><div class="content"><p>Hi,<br></p><p>I think (and hope) that this is the proper forum for a few questions wrt to libdispatch, otherwise any pointers are appreciated.<br></p><p>We are currently using libdispatch extensively on Linux (and Solaris for a while longer…) based on the previous version available from Mac OS forge (with later additions merged from opensource.apple.com) over time.<br></p><p>I have a few questions on how (particularly Apple folks) view this going forward:<br></p><p>First, the previous port to Linux/Solaris of libdispatch was dependent on libkqueue and more importantly on libpthread_workqueue (to have some heuristics for managing the number of threads when lacking kernel support).<br></p><p>How do you view this, would you consider integrating support for libpthread_workqueue, or would you have another preference for how to manage this on other platforms (Linux for starters, but essentially any lacking the pthread_workqueue interface)?<br></p><p>Secondly, we have extended the public libdispatch API internally with one more flavor of dispatching, let’s call it ‘dispatch_async_inline’ - the semantics being ‘perform the processing of the work synchronously if we wouldn’t block the calling thread, if we would block, instead perform the work as a normal dispatch_async’.<br></p><p>Would such a change be considered to be integrated, or should we keep our internal diffs indefinitely? Just to understand if it is worth the effort with a nicely packaged pull request or not...<br></p><p>The rationale for the API is that we are quite latency sensitive and want to use inline processing up until the point where we can’t keep up with the available work, at which point we would switch to asynchronous processing seamlessly (we have multiple producers). This means that the thread calling this API can be stolen for a significant amount of time (emptying the queue it was assigned to), but when the system is under ‘light&#39; load, we don’t need to incur the wakeup penalty for a completely asynchronous dispatch.<br></p><p>Cheers,<br></p><p>Joakim<br></p><p>PS Big kudos to whoever at Apple is responsible for driving fundamentals like this out as OSS...<br></p><p><br>________________________________<br></p><p>This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/be4c3c3b76631a155e1358db48066692?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Tony Parker</string> &lt;anthony.parker at apple.com&gt;<p>December  7, 2015 at 11:00:00am</p></header><div class="content"><p>Hi Joakim,<br></p><p>&gt; On Dec 7, 2015, at 4:55 AM, Joakim Hassila via swift-corelibs-dev &lt;swift-corelibs-dev at swift.org&gt; wrote:<br>&gt; <br>&gt; Hi,<br>&gt; <br>&gt; I think (and hope) that this is the proper forum for a few questions wrt to libdispatch, otherwise any pointers are appreciated.<br>&gt; <br></p><p>Yup, you’re in the right place.<br></p><p>&gt; We are currently using libdispatch extensively on Linux (and Solaris for a while longer…) based on the previous version available from Mac OS forge (with later additions merged from opensource.apple.com) over time.<br>&gt; <br>&gt; I have a few questions on how (particularly Apple folks) view this going forward:<br>&gt; <br>&gt; First, the previous port to Linux/Solaris of libdispatch was dependent on libkqueue and more importantly on libpthread_workqueue (to have some heuristics for managing the number of threads when lacking kernel support).<br>&gt; <br>&gt; How do you view this, would you consider integrating support for libpthread_workqueue, or would you have another preference for how to manage this on other platforms (Linux for starters, but essentially any lacking the pthread_workqueue interface)?<br>&gt; <br></p><p>I think it’s reasonable to continue to depend on libkqueue here where we can. We may have to have some kind of config option to use pure userspace stuff on certain platforms. I’m also open to the idea of getting something with fewer dependencies and lower performance done as an early first step, so we can unblock all of the API above libdispatch that wants to just use queues.<br></p><p>&gt; Secondly, we have extended the public libdispatch API internally with one more flavor of dispatching, let’s call it ‘dispatch_async_inline’ - the semantics being ‘perform the processing of the work synchronously if we wouldn’t block the calling thread, if we would block, instead perform the work as a normal dispatch_async’.<br>&gt; <br>&gt; Would such a change be considered to be integrated, or should we keep our internal diffs indefinitely? Just to understand if it is worth the effort with a nicely packaged pull request or not…<br></p><p>&gt; The rationale for the API is that we are quite latency sensitive and want to use inline processing up until the point where we can’t keep up with the available work, at which point we would switch to asynchronous processing seamlessly (we have multiple producers). This means that the thread calling this API can be stolen for a significant amount of time (emptying the queue it was assigned to), but when the system is under ‘light&#39; load, we don’t need to incur the wakeup penalty for a completely asynchronous dispatch.<br>&gt; <br></p><p>Our most important goal for year one is to get the core library implementations up to date with where we are on Darwin on platforms like Linux. API changes are not out of the question but we have to make sure they align with that goal. This is the right place to discuss them, though. We’ll be in a much better place to evaluate it when we get dispatch building &amp; running.<br></p><p>&gt; Cheers,<br>&gt; <br>&gt; Joakim<br>&gt; <br>&gt; PS Big kudos to whoever at Apple is responsible for driving fundamentals like this out as OSS…<br>&gt; <br></p><p>Thanks for your interest in the project!<br></p><p>- Tony<br></p><p><br>&gt; <br>&gt; ________________________________<br>&gt; <br>&gt; This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br>&gt; _______________________________________________<br>&gt; swift-corelibs-dev mailing list<br>&gt; swift-corelibs-dev at swift.org<br>&gt; https://lists.swift.org/mailman/listinfo/swift-corelibs-dev<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/8daa9d0c5cf56d891ee1e33571342032?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Joakim Hassila</string> &lt;Joakim.Hassila at orc-group.com&gt;<p>December  8, 2015 at 02:00:00pm</p></header><div class="content"><p>Hi Tony,<br></p><p>&gt; On 7 dec. 2015, at 20:37, Tony Parker &lt;anthony.parker at apple.com&gt; wrote:<br>&gt; I think it’s reasonable to continue to depend on libkqueue here where we can. We may have to have some kind of config option to use pure userspace stuff on certain platforms. I’m also open to the idea of getting something with fewer dependencies and lower performance done as an early first step, so we can unblock all of the API above libdispatch that wants to just use queues.<br></p><p>That would make sense - just want to point out that libkqueue and libpwq are separate - the same question posed for libpwq in a separate mail would be relevant for libkqueue as well - would closer integration make sense, or just keep things separate?<br></p><p>&gt;&gt; Our most important goal for year one is to get the core library implementations up to date with where we are on Darwin on platforms like Linux. API changes are not out of the question but we have to make sure they align with that goal. This is the right place to discuss them, though. We’ll be in a much better place to evaluate it when we get dispatch building &amp; running.<br></p><p>Thanks, to complete the bringup of the core libraries makes sense, we’d just want to understand how to approach (the very few) API additions we’ve made - and it’s good its the right forum.<br></p><p>Cheers,<br></p><p>Joakim<br></p><p><br>________________________________<br></p><p>This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br></p></div></li></ul></li><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/6451ee8093c9cedc94f6c813b4dde2c5?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Kevin Ballard</string> &lt;kevin at sb.org&gt;<p>December  7, 2015 at 12:00:00pm</p></header><div class="content"><p>On Mon, Dec 7, 2015, at 04:55 AM, Joakim Hassila via swift-corelibs-dev wrote:<br>&gt; Secondly, we have extended the public libdispatch API internally with<br>&gt; one more flavor of dispatching, let’s call it ‘dispatch_async_inline’<br>&gt; - the semantics being ‘perform the processing of the work<br>&gt; synchronously if we wouldn’t block the calling thread, if we would<br>&gt; block, instead perform the work as a normal dispatch_async’.<br>&gt;<br>&gt; Would such a change be considered to be integrated, or should we keep<br>&gt; our internal diffs indefinitely? Just to understand if it is worth the<br>&gt; effort with a nicely packaged pull request or not...<br>&gt;<br>&gt; The rationale for the API is that we are quite latency sensitive and<br>&gt; want to use inline processing up until the point where we can’t keep<br>&gt; up with the available work, at which point we would switch to<br>&gt; asynchronous processing seamlessly (we have multiple producers). This<br>&gt; means that the thread calling this API can be stolen for a significant<br>&gt; amount of time (emptying the queue it was assigned to), but when the<br>&gt; system is under ‘light&#39; load, we don’t need to incur the wakeup<br>&gt; penalty for a completely asynchronous dispatch.<br></p><p>I actually have an outstanding radar asking for this exact<br>functionality. My proposal called it `dispatch_try_sync()`, which didn&#39;t<br>actually call the dispatch_async() automatically but simply returned a<br>boolean value telling you if it ran the code. My use-case here wasn&#39;t<br>actually that I wanted to run the code async, but that I needed to do<br>two operations on a realtime thread in any order, one of which needed to<br>be on a queue, so I wanted to do something like<br></p><p>BOOL done = dispatch_try_sync(queue, ^{ ... }); do_other_work(); if<br>(!done) {    dispatch_sync(queue, ^{ ... }); }<br></p><p>My radar is still open (rdar://problem/16436943), but it got a response<br>as follows:<br></p><p>&gt; I think the best way to &quot;emulate&quot; this is to use a DATA_OR source, and<br>&gt; not semaphores or other things like that.<br>&gt;<br>&gt; Most of the issues that I&#39;ve seen with trylock() tends to be uses<br>&gt; looking like this:<br>&gt;<br>&gt; again:  if (trylock()) {    do {      clear_marker();      do_job();<br>&gt; } while(has_marker());     unlock();  } else if (!has_marker()) {<br>&gt; set_marker();    goto again;  }<br>&gt;<br>&gt; and all unlockers check for the marker to do the said job before<br>&gt; unlock basically.<br>&gt;<br>&gt; The thing is, most of the people use that wrongly and don&#39;t loop<br>&gt; properly making those coalescing checks racy, that&#39;s what dispatch<br>&gt; DATA_OR sources are for.<br>&gt;<br>&gt; Many other uses can also be replaced with a dispatch_async()<br>&gt;<br>&gt; and it&#39;s very clear that the reporter can do exactly what he wants<br>&gt; with a DATA_OR source. We should have a way to make sources acts as<br>&gt; barriers (which I have a patch for) else we only provide half the<br>&gt; required primitives.<br>&gt;<br>&gt; I don&#39;t see a compelling use case that can&#39;t be solved elegantly with<br>&gt; data sources today.<br>&gt;<br>&gt; Using a DISPATCH_SOURCE_DATA_OR with a latch is a good alternative to<br>&gt; what you are doing.<br>&gt;<br>&gt; We are continuing to work on this issue, and will follow up with<br>&gt; you again.<br></p><p>-Kevin Ballard<br>-------------- next part --------------<br>An HTML attachment was scrubbed...<br>URL: &lt;https://lists.swift.org/pipermail/swift-corelibs-dev/attachments/20151207/ce638ae5/attachment.html&gt;<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/0db24e79de1d6e82cf6327b091903b1b?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Pierre Habouzit</string> &lt;phabouzit at apple.com&gt;<p>December  7, 2015 at 02:00:00pm</p></header><div class="content"><p>&gt; On Dec 7, 2015, at 12:30 PM, Kevin Ballard via swift-corelibs-dev &lt;swift-corelibs-dev at swift.org&gt; wrote:<br>&gt; <br>&gt; On Mon, Dec 7, 2015, at 04:55 AM, Joakim Hassila via swift-corelibs-dev wrote:<br>&gt; Secondly, we have extended the public libdispatch API internally with one<br>&gt; more flavor of dispatching, let’s call it ‘dispatch_async_inline’ - the<br>&gt; semantics being ‘perform the processing of the work synchronously if we<br>&gt; wouldn’t block the calling thread, if we would block, instead perform the<br>&gt; work as a normal dispatch_async’.<br>&gt;  <br>&gt; Would such a change be considered to be integrated, or should we keep our<br>&gt; internal diffs indefinitely? Just to understand if it is worth the effort<br>&gt; with a nicely packaged pull request or not...<br>&gt;  <br>&gt; The rationale for the API is that we are quite latency sensitive and want<br>&gt; to use inline processing up until the point where we can’t keep up with<br>&gt; the available work, at which point we would switch to asynchronous<br>&gt; processing seamlessly (we have multiple producers). This means that the<br>&gt; thread calling this API can be stolen for a significant amount of time<br>&gt; (emptying the queue it was assigned to), but when the system is under<br>&gt; ‘light&#39; load, we don’t need to incur the wakeup penalty for a completely<br>&gt; asynchronous dispatch.<br>&gt;  <br>&gt; I actually have an outstanding radar asking for this exact functionality. My proposal called it `dispatch_try_sync()`, which didn&#39;t actually call the dispatch_async() automatically but simply returned a boolean value telling you if it ran the code. My use-case here wasn&#39;t actually that I wanted to run the code async, but that I needed to do two operations on a realtime thread in any order, one of which needed to be on a queue, so I wanted to do something like<br>&gt;  <br>&gt; BOOL done = dispatch_try_sync(queue, ^{ ... });<br>&gt; do_other_work();<br>&gt; if (!done) {<br>&gt;     dispatch_sync(queue, ^{ ... });<br>&gt; }<br>&gt;  <br>&gt; My radar is still open (rdar://problem/16436943 &lt;rdar://problem/16436943&gt;), but it got a response as follows:<br>&gt;  <br>&gt; I think the best way to &quot;emulate&quot; this is to use a DATA_OR source, and not semaphores or other things like that.<br>&gt;  <br>&gt; Most of the issues that I&#39;ve seen with trylock() tends to be uses looking like this:<br>&gt;  <br>&gt; again:<br>&gt;   if (trylock()) {<br>&gt;     do {<br>&gt;       clear_marker();<br>&gt;       do_job();<br>&gt;      } while(has_marker());<br>&gt;      unlock();<br>&gt;   } else if (!has_marker()) {<br>&gt;     set_marker();<br>&gt;     goto again;<br>&gt;   }<br>&gt;  <br>&gt; and all unlockers check for the marker to do the said job before unlock basically.<br>&gt;  <br>&gt; The thing is, most of the people use that wrongly and don&#39;t loop properly making those coalescing checks racy, that&#39;s what dispatch DATA_OR sources are for.<br>&gt;  <br>&gt; Many other uses can also be replaced with a dispatch_async()<br>&gt;  <br>&gt; and it&#39;s very clear that the reporter can do exactly what he wants with a DATA_OR source. We should have a way to make sources acts as barriers (which I have a patch for) else we only provide half the required primitives.<br>&gt;  <br>&gt; I don&#39;t see a compelling use case that can&#39;t be solved elegantly with data sources today.<br>&gt;  <br>&gt; Using a DISPATCH_SOURCE_DATA_OR with a latch is a good alternative to what you are doing.<br>&gt;  <br>&gt; We are continuing to work on this issue, and will follow up with you again.<br></p><p>Hi Joakim, Kevin,<br></p><p>[ Full disclosure, I made that reply in rdar://problem/16436943 &lt;rdar://problem/16436943&gt; and your use case was slightly different IIRC but you’re right it’s a close enough problem ]<br></p><p>Dispatch internally has a notion of something that does almost that, called _dispatch_barrier_trysync_f[1]. However, it is used internally to serialize state changes on sources and queues such as setting the target queue or event handlers.<br></p><p>The problem is that this call bypasses the target queue hierarchy in its fastpath, which while it’s correct when changing the state of a given source or queue, is generally the wrong thing to do. Let’s consider this code assuming the dispatch_barrier_trysync()<br></p><p><br>    dispatch_queue_t outer = dispatch_queue_create(&quot;outer&quot;, NULL);<br>    dispatch_queue_t inner = dispatch_queue_create(&quot;inner&quot;, NULL);<br>    dispatch_set_target_queue(outer, inner);<br></p><p>    dispatch_async(inner, ^{<br>        // write global state protected by inner<br>    });<br>    dispatch_barrier_trysync(outer, ^{<br>        // write global state protected by inner<br>    });<br></p><p><br>Then if it works like the internal version we have today, the code above has a data race, which we’ll all agree is bad.<br>Or we do an API version that when the queue you do the trysync on is not targetted at a global root queue always go through async, and that is weird, because the performance characteristics would completely depend on the target queue hierarchy, which when layering and frameworks start to be at play, is a bad characteristic for a good API.<br></p><p>Or we don’t give up right away when the hierarchy is deep, but then that means that dispatch_trysync would need to be able to unwind all the locks it took, and then you have ordering issues because enqueuing that block that couldn’t run synchronously may end up being after another one and break the FIFO ordering of queues. Respecting this which is a desired property of our API and getting an efficient implementation are somehow at odds.<br></p><p>The other argument against trysync that way, is that during testing trysync would almost always go through the non contended codepath, and lead developers to not realize that they should have taken copies of variables and the like (this is less of a problem on Darwin with obj-c and ARC), but trysync running on the same thread will hide that. except that once it starts being contended in production, it’ll bite you hard with memory corruption everywhere.<br></p><p>Technically what you’re after is that bringing up a new thread is very costly and that you’d rather use the one that’s asyncing the request because it will soon give up control. The wake up of a queue isn’t that expensive, in the sense that the overhead of dispatch_sync() in terms of memory barriers and locking is more or less comparable. What’s expensive is creating a thread to satisfy this enqueue.<br></p><p>In my opinion, to get the win you’re after, you’d rather want an async() version that if it wakes up the target queue hierarchy up to the root then you  want to have more resistance in bringing up a new thread to satisfy that request. Fortunately, the overcommit property of queues could be used by a thread pool to decide to apply that resistance. There are various parts of the thread pool handling (especially without kernel work queues support) that could get some love to get these exact benefits without changing the API.<br></p><p><br>[1] https://github.com/apple/swift-corelibs-libdispatch/blob/394d9a1c8be525cde8d9dd9fb8cef8308089b9c5/src/queue.c#L3089<br></p><p>-Pierre<br></p><p>-------------- next part --------------<br>An HTML attachment was scrubbed...<br>URL: &lt;https://lists.swift.org/pipermail/swift-corelibs-dev/attachments/20151207/a3d649f5/attachment.html&gt;<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/8daa9d0c5cf56d891ee1e33571342032?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Joakim Hassila</string> &lt;Joakim.Hassila at orc-group.com&gt;<p>December  8, 2015 at 03:00:00pm</p></header><div class="content"><p>Hi Pierre,<br></p><p>Thanks for the good explanation, will try to respond inline below:<br></p><p>On 7 dec. 2015, at 23:10, Pierre Habouzit &lt;phabouzit at apple.com&lt;mailto:phabouzit at apple.com&gt;&gt; wrote:<br></p><p>Hi Joakim, Kevin,<br></p><p>[ Full disclosure, I made that reply in rdar://problem/16436943 and your use case was slightly different IIRC but you’re right it’s a close enough problem ]<br></p><p>Dispatch internally has a notion of something that does almost that, called _dispatch_barrier_trysync_f[1]. However, it is used internally to serialize state changes on sources and queues such as setting the target queue or event handlers.<br></p><p>The problem is that this call bypasses the target queue hierarchy in its fastpath, which while it’s correct when changing the state of a given source or queue, is generally the wrong thing to do. Let’s consider this code assuming the dispatch_barrier_trysync()<br></p><p><br>    dispatch_queue_t outer = dispatch_queue_create(&quot;outer&quot;, NULL);<br>    dispatch_queue_t inner = dispatch_queue_create(&quot;inner&quot;, NULL);<br>    dispatch_set_target_queue(outer, inner);<br></p><p>    dispatch_async(inner, ^{<br>        // write global state protected by inner<br>    });<br>    dispatch_barrier_trysync(outer, ^{<br>        // write global state protected by inner<br>    });<br></p><p><br>Then if it works like the internal version we have today, the code above has a data race, which we’ll all agree is bad.<br>Or we do an API version that when the queue you do the trysync on is not targetted at a global root queue always go through async, and that is weird, because the performance characteristics would completely depend on the target queue hierarchy, which when layering and frameworks start to be at play, is a bad characteristic for a good API.<br></p><p>Yes, we could currently assume that we only targeted a root queue for our use case, so our implementation has this limitation (so it is not a valid general solution as you say).<br></p><p>It would perhaps be a bit strange to have different performance characteristics depending on the target queue hierarchy as you say, but there are already some performance differences in actual behavior if using e.g. an overcommit queue vs a non, so perhaps another option would be to have this as an optional queue attribute instead of an additional generic API (queue attribute ’steal calling thread for inline processing of requests if the queue was empty when dispatching’) …?<br></p><p><br>Or we don’t give up right away when the hierarchy is deep, but then that means that dispatch_trysync would need to be able to unwind all the locks it took, and then you have ordering issues because enqueuing that block that couldn’t run synchronously may end up being after another one and break the FIFO ordering of queues. Respecting this which is a desired property of our API and getting an efficient implementation are somehow at odds.<br></p><p>Yes, agree it is a desirable property of the API to retain the ordering.<br></p><p>The other argument against trysync that way, is that during testing trysync would almost always go through the non contended codepath, and lead developers to not realize that they should have taken copies of variables and the like (this is less of a problem on Darwin with obj-c and ARC), but trysync running on the same thread will hide that. except that once it starts being contended in production, it’ll bite you hard with memory corruption everywhere.<br></p><p>Less of an issue for us as we depend on the _f interfaces throughout due to portability concerns, but fair point.<br></p><p>Technically what you’re after is that bringing up a new thread is very costly and that you’d rather use the one that’s asyncing the request because it will soon give up control. The wake up of a queue isn’t that expensive, in the sense that the overhead of dispatch_sync() in terms of memory barriers and locking is more or less comparable. What’s expensive is creating a thread to satisfy this enqueue.<br></p><p>Yes, in fact, bringing up a new thread is so costly that we keep a pool around in the libpwq implementation. Unfortunately we would often see double-digit microsecond latency incurred by this, which is unacceptable for us, so we had to (for some configurations/special deployments) have a dedicated spin thread that will grab the next queue to work on (that cut down the latency with a factor of 10 or so) and the next thread woken from the thread pool would take over a spinner…<br></p><p>In my opinion, to get the win you’re after, you’d rather want an async() version that if it wakes up the target queue hierarchy up to the root then you  want to have more resistance in bringing up a new thread to satisfy that request. Fortunately, the overcommit property of queues could be used by a thread pool to decide to apply that resistance. There are various parts of the thread pool handling (especially without kernel work queues support) that could get some love to get these exact benefits without changing the API.<br></p><p>That would indeed be a very interesting idea, the problem is that the thread using ‘dispatch_barrier_trysync’ is not returning to the pthread_workqueue pool to grab the next dispatch queue for processing, but is instead going back to block on a syscall (e.g. read() from a socket) - and even the latency to wake up a thread (as is commonly done now) with mutex/condition signaling is way too slow for the use case we have (thus the very ugly workaround with a spin thread for some deployments).<br></p><p>Essentially, for these kind of operations we really want to avoid all context switches as long as we can keep up with the rate of inbound data, and in general such dynamics would be a nice property to have - if the thread performing the async call was known to always return to the global pwq thread pool, it would be nicely solved by applying resistance as you suggest, the problem is what to do when it gets blocked and you thus get stuck.<br></p><p>Perhaps we have to live with the limited implementation we have for practical purposes, but I have the feeling that the behavior we are after would be useful for other use cases, perhaps the queue attribute suggested above could be another way of expressing it without introducing new dispatch API.<br></p><p>Cheers,<br></p><p>Joakim<br></p><p><br>________________________________<br></p><p>This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br>-------------- next part --------------<br>An HTML attachment was scrubbed...<br>URL: &lt;https://lists.swift.org/pipermail/swift-corelibs-dev/attachments/20151208/7437ceb3/attachment.html&gt;<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/0db24e79de1d6e82cf6327b091903b1b?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Pierre Habouzit</string> &lt;phabouzit at apple.com&gt;<p>December  8, 2015 at 08:00:00am</p></header><div class="content"><p>-Pierre<br></p><p>&gt; On Dec 8, 2015, at 7:34 AM, Joakim Hassila via swift-corelibs-dev &lt;swift-corelibs-dev at swift.org&gt; wrote:<br>&gt; <br>&gt; Hi Pierre,<br>&gt; <br>&gt; Thanks for the good explanation, will try to respond inline below:<br>&gt; <br>&gt;&gt; On 7 dec. 2015, at 23:10, Pierre Habouzit &lt;phabouzit at apple.com &lt;mailto:phabouzit at apple.com&gt;&gt; wrote:<br>&gt;&gt; <br>&gt;&gt; Hi Joakim, Kevin,<br>&gt;&gt; <br>&gt;&gt; [ Full disclosure, I made that reply in rdar://problem/16436943 &lt;rdar://problem/16436943&gt; and your use case was slightly different IIRC but you’re right it’s a close enough problem ]<br>&gt;&gt; <br>&gt;&gt; Dispatch internally has a notion of something that does almost that, called _dispatch_barrier_trysync_f[1]. However, it is used internally to serialize state changes on sources and queues such as setting the target queue or event handlers.<br>&gt;&gt; <br>&gt;&gt; The problem is that this call bypasses the target queue hierarchy in its fastpath, which while it’s correct when changing the state of a given source or queue, is generally the wrong thing to do. Let’s consider this code assuming the dispatch_barrier_trysync()<br>&gt;&gt; <br>&gt;&gt; <br>&gt;&gt;     dispatch_queue_t outer = dispatch_queue_create(&quot;outer&quot;, NULL);<br>&gt;&gt;     dispatch_queue_t inner = dispatch_queue_create(&quot;inner&quot;, NULL);<br>&gt;&gt;     dispatch_set_target_queue(outer, inner);<br>&gt;&gt; <br>&gt;&gt;     dispatch_async(inner, ^{<br>&gt;&gt;         // write global state protected by inner<br>&gt;&gt;     });<br>&gt;&gt;     dispatch_barrier_trysync(outer, ^{<br>&gt;&gt;         // write global state protected by inner<br>&gt;&gt;     });<br>&gt;&gt; <br>&gt;&gt; <br>&gt;&gt; Then if it works like the internal version we have today, the code above has a data race, which we’ll all agree is bad.<br>&gt;&gt; Or we do an API version that when the queue you do the trysync on is not targetted at a global root queue always go through async, and that is weird, because the performance characteristics would completely depend on the target queue hierarchy, which when layering and frameworks start to be at play, is a bad characteristic for a good API.<br>&gt; <br>&gt; Yes, we could currently assume that we only targeted a root queue for our use case, so our implementation has this limitation (so it is not a valid general solution as you say). <br>&gt; <br>&gt; It would perhaps be a bit strange to have different performance characteristics depending on the target queue hierarchy as you say, but there are already some performance differences in actual behavior if using e.g. an overcommit queue vs a non, so perhaps another option would be to have this as an optional queue attribute instead of an additional generic API (queue attribute ’steal calling thread for inline processing of requests if the queue was empty when dispatching’) …?<br></p><p>My point is, adding API to dispatch is not something we do lightly. I’m not keen on an interface that only works for base queues. Mac OS and iOS code where dispatchy code is pervasive, more than 2 queue deep queues hierarchy is very common typically.<br></p><p>&gt;&gt; Or we don’t give up right away when the hierarchy is deep, but then that means that dispatch_trysync would need to be able to unwind all the locks it took, and then you have ordering issues because enqueuing that block that couldn’t run synchronously may end up being after another one and break the FIFO ordering of queues. Respecting this which is a desired property of our API and getting an efficient implementation are somehow at odds.<br>&gt; <br>&gt; Yes, agree it is a desirable property of the API to retain the ordering.<br>&gt; <br>&gt;&gt; The other argument against trysync that way, is that during testing trysync would almost always go through the non contended codepath, and lead developers to not realize that they should have taken copies of variables and the like (this is less of a problem on Darwin with obj-c and ARC), but trysync running on the same thread will hide that. except that once it starts being contended in production, it’ll bite you hard with memory corruption everywhere.<br>&gt; <br>&gt; Less of an issue for us as we depend on the _f interfaces throughout due to portability concerns, but fair point.<br>&gt; <br>&gt;&gt; Technically what you’re after is that bringing up a new thread is very costly and that you’d rather use the one that’s asyncing the request because it will soon give up control. The wake up of a queue isn’t that expensive, in the sense that the overhead of dispatch_sync() in terms of memory barriers and locking is more or less comparable. What’s expensive is creating a thread to satisfy this enqueue.<br>&gt; <br>&gt; Yes, in fact, bringing up a new thread is so costly that we keep a pool around in the libpwq implementation. Unfortunately we would often see double-digit microsecond latency incurred by this, which is unacceptable for us, so we had to (for some configurations/special deployments) have a dedicated spin thread that will grab the next queue to work on (that cut down the latency with a factor of 10 or so) and the next thread woken from the thread pool would take over a spinner…<br>&gt; <br>&gt;&gt; In my opinion, to get the win you’re after, you’d rather want an async() version that if it wakes up the target queue hierarchy up to the root then you  want to have more resistance in bringing up a new thread to satisfy that request. Fortunately, the overcommit property of queues could be used by a thread pool to decide to apply that resistance. There are various parts of the thread pool handling (especially without kernel work queues support) that could get some love to get these exact benefits without changing the API.<br>&gt; <br>&gt; That would indeed be a very interesting idea, the problem is that the thread using ‘dispatch_barrier_trysync’ is not returning to the pthread_workqueue pool to grab the next dispatch queue for processing, but is instead going back to block on a syscall (e.g. read() from a socket) - and even the latency to wake up a thread (as is commonly done now) with mutex/condition signaling is way too slow for the use case we have (thus the very ugly workaround with a spin thread for some deployments).<br>&gt; <br>&gt; Essentially, for these kind of operations we really want to avoid all context switches as long as we can keep up with the rate of inbound data, and in general such dynamics would be a nice property to have - if the thread performing the async call was known to always return to the global pwq thread pool, it would be nicely solved by applying resistance as you suggest, the problem is what to do when it gets blocked and you thus get stuck.<br>&gt; <br>&gt; Perhaps we have to live with the limited implementation we have for practical purposes, but I have the feeling that the behavior we are after would be useful for other use cases, perhaps the queue attribute suggested above could be another way of expressing it without introducing new dispatch API. <br></p><p>I completely agree with you, but I think that the way to address this is by making the thread pool smarter, not having the developper have to sprinkle his code with dispatch_barrier_trysync() where he feels like it. Using it properly require a deep understanding of the implementation of dispatch he’s using and changes on each platform / version combination. that’s not really the kind of interface we want to build.<br></p><p>“overcommit” is exactly the hint you’re after as far as the queue is concerned. It means “if I’m woken up, bring up a new thread provided it doesn’t blow up the system, no matter what”. So make your queue non overcommit by targetting it manually to dispatch_get_global_queue(0, 0) (that one isn’t overcommit), and make the thread pool smarter. That’s the right way to go and the design-compatible way to do it.<br></p><p>If your thread block in read() then I would argue that it should use a READ dispatch source instead, that way, the source would get enqueued *after* your async and you can ping pong. Doing blocking read()s is not dispatchy at all and will cause you all sorts of problems like that one, because re-async doesn’t work for you.<br></p><p>-Pierre<br></p><p>-------------- next part --------------<br>An HTML attachment was scrubbed...<br>URL: &lt;https://lists.swift.org/pipermail/swift-corelibs-dev/attachments/20151208/ae19fdc9/attachment.html&gt;<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/8daa9d0c5cf56d891ee1e33571342032?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Joakim Hassila</string> &lt;Joakim.Hassila at orc-group.com&gt;<p>December 10, 2015 at 09:00:00am</p></header><div class="content"><p>&gt; On 8 dec. 2015, at 17:07, Pierre Habouzit &lt;phabouzit at apple.com&gt; wrote:<br>&gt;<br>&gt; My point is, adding API to dispatch is not something we do lightly. I’m not keen on an interface that only works for base queues. Mac OS and iOS code where dispatchy code is pervasive, more than 2 queue deep queues hierarchy is very common typically.<br></p><p>Gotcha.<br></p><p>&gt;<br>&gt;&gt;<br>&gt;&gt; That would indeed be a very interesting idea, the problem is that the thread using ‘dispatch_barrier_trysync’ is not returning to the pthread_workqueue pool to grab the next dispatch queue for processing, but is instead going back to block on a syscall (e.g. read() from a socket) - and even the latency to wake up a thread (as is commonly done now) with mutex/condition signaling is way too slow for the use case we have (thus the very ugly workaround with a spin thread for some deployments).<br>&gt;&gt; &lt;snip&gt;<br>&gt;&gt; Perhaps we have to live with the limited implementation we have for practical purposes, but I have the feeling that the behavior we are after would be useful for other use cases, perhaps the queue attribute suggested above could be another way of expressing it without introducing new dispatch API.<br>&gt;<br>&gt; I completely agree with you, but I think that the way to address this is by making the thread pool smarter, not having the developper have to sprinkle his code with dispatch_barrier_trysync() where he feels like it. Using it properly require a deep understanding of the implementation of dispatch he’s using and changes on each platform / version combination. that’s not really the kind of interface we want to build.<br>&gt;<br>&gt; “overcommit” is exactly the hint you’re after as far as the queue is concerned. It means “if I’m woken up, bring up a new thread provided it doesn’t blow up the system, no matter what”. So make your queue non overcommit by targetting it manually to dispatch_get_global_queue(0, 0) (that one isn’t overcommit), and make the thread pool smarter. That’s the right way to go and the design-compatible way to do it.<br></p><p>Ok, this is interesting (and probably just points out my misunderstanding of the intended semantics of the overcommit flag) - the part with “doesn’t blow up the system” is actually not clear from the header files, it says:<br></p><p>++++++<br> * @constant DISPATCH_QUEUE_OVERCOMMIT<br> * The queue will create a new thread for invoking blocks, regardless of how<br> * busy the computer is.<br>++++++<br></p><p>The ‘regardless of how busy the computer is’ was also the implementation of overcommit queues in pwq, so we essentially banned the usage of them here internally as the semantics where not very usable for us, as a new thread was always created (and we do use a fairly large number of dispatch queues).<br></p><p>If we would have semantics like:<br>“overcommit” - &quot;if I’m woken up, bring up a new thread provided it doesn’t blow up the system, no matter what” and the definition of “blowing up the system” is to not have more concurrent running threads than there are active cores<br>“non overcommit” - “only bring up a new thread a provided that enough ‘pressure’ is applied” (to allow for essentially the ping pong you suggest)<br></p><p>Then I think we can work with making the thread pool smarter and get desired behavior - will think a bit more about it (I think that some care would be required to not have essentially lost wakeups for the non overcommit variant in that case), but it feels like a possibly better way forward, thanks.<br></p><p>Would such interpretation of the overcommit attribute semantics be reasonable? (we wouldn’t want to have a completely different view of it to keep the API behavior robust across platforms)<br></p><p>&gt; If your thread block in read() then I would argue that it should use a READ dispatch source instead, that way, the source would get enqueued *after* your async and you can ping pong. Doing blocking read()s is not dispatchy at all and will cause you all sorts of problems like that one, because re-async doesn’t work for you.<br></p><p>Here we are a bit living with legacy considerations, but perhaps one possible way we are discussing is if such threads could use the pwq API (at the tail end) to facilitate the behavior you suggest.<br></p><p>I.e. pseudocode:<br></p><p>f() // legacy non-dispatchy code<br>{<br>  read()                                  // get some new work<br>  dispatch_async()                        // dispatch the work on a non-overcommit queue<br>  pthread_workqueue_additem_np(q, f, ...) // repeat f(), switch between overcommit/nonovercommit target work queues as needed/desired, this thread could thus be stolen to process the above dispatch_async<br>}<br></p><p>Thanks!<br></p><p>Joakim<br></p><p><br>________________________________<br></p><p>This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/0db24e79de1d6e82cf6327b091903b1b?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Pierre Habouzit</string> &lt;phabouzit at apple.com&gt;<p>December 10, 2015 at 10:00:00am</p></header><div class="content"><p>&gt; On Dec 10, 2015, at 1:06 AM, Joakim Hassila via swift-corelibs-dev &lt;swift-corelibs-dev at swift.org&gt; wrote:<br>&gt; <br>&gt;&gt; On 8 dec. 2015, at 17:07, Pierre Habouzit &lt;phabouzit at apple.com&gt; wrote:<br>&gt;&gt; <br>&gt;&gt; My point is, adding API to dispatch is not something we do lightly. I’m not keen on an interface that only works for base queues. Mac OS and iOS code where dispatchy code is pervasive, more than 2 queue deep queues hierarchy is very common typically.<br>&gt; <br>&gt; Gotcha.<br>&gt; <br>&gt;&gt; <br>&gt;&gt;&gt; <br>&gt;&gt;&gt; That would indeed be a very interesting idea, the problem is that the thread using ‘dispatch_barrier_trysync’ is not returning to the pthread_workqueue pool to grab the next dispatch queue for processing, but is instead going back to block on a syscall (e.g. read() from a socket) - and even the latency to wake up a thread (as is commonly done now) with mutex/condition signaling is way too slow for the use case we have (thus the very ugly workaround with a spin thread for some deployments).<br>&gt;&gt;&gt; &lt;snip&gt;<br>&gt;&gt;&gt; Perhaps we have to live with the limited implementation we have for practical purposes, but I have the feeling that the behavior we are after would be useful for other use cases, perhaps the queue attribute suggested above could be another way of expressing it without introducing new dispatch API.<br>&gt;&gt; <br>&gt;&gt; I completely agree with you, but I think that the way to address this is by making the thread pool smarter, not having the developper have to sprinkle his code with dispatch_barrier_trysync() where he feels like it. Using it properly require a deep understanding of the implementation of dispatch he’s using and changes on each platform / version combination. that’s not really the kind of interface we want to build.<br>&gt;&gt; <br>&gt;&gt; “overcommit” is exactly the hint you’re after as far as the queue is concerned. It means “if I’m woken up, bring up a new thread provided it doesn’t blow up the system, no matter what”. So make your queue non overcommit by targetting it manually to dispatch_get_global_queue(0, 0) (that one isn’t overcommit), and make the thread pool smarter. That’s the right way to go and the design-compatible way to do it.<br>&gt; <br>&gt; Ok, this is interesting (and probably just points out my misunderstanding of the intended semantics of the overcommit flag) - the part with “doesn’t blow up the system” is actually not clear from the header files, it says:<br></p><p>on OS X, the “doesn’t blow up the system” part is, you still have less than 512 threads and enough threads allowed globally on that host, it’s not really a very strong limit.<br></p><p><br>&gt; ++++++<br>&gt; * @constant DISPATCH_QUEUE_OVERCOMMIT<br>&gt; * The queue will create a new thread for invoking blocks, regardless of how<br>&gt; * busy the computer is.<br>&gt; ++++++<br>&gt; <br>&gt; The ‘regardless of how busy the computer is’ was also the implementation of overcommit queues in pwq, so we essentially banned the usage of them here internally as the semantics where not very usable for us, as a new thread was always created (and we do use a fairly large number of dispatch queues).<br>&gt; <br>&gt; If we would have semantics like:<br>&gt; “overcommit” - &quot;if I’m woken up, bring up a new thread provided it doesn’t blow up the system, no matter what” and the definition of “blowing up the system” is to not have more concurrent running threads than there are active cores<br>&gt; “non overcommit” - “only bring up a new thread a provided that enough ‘pressure’ is applied” (to allow for essentially the ping pong you suggest)<br>&gt; <br>&gt; Then I think we can work with making the thread pool smarter and get desired behavior - will think a bit more about it (I think that some care would be required to not have essentially lost wakeups for the non overcommit variant in that case), but it feels like a possibly better way forward, thanks.<br>&gt; <br>&gt; Would such interpretation of the overcommit attribute semantics be reasonable? (we wouldn’t want to have a completely different view of it to keep the API behavior robust across platforms)<br></p><p>The overcommit intent was that “if I’m on a single core machine and I wake up that queue but I myself keep a thread busy, would the program livelock because that queue I just woke up wouldn’t wakeup a thread”. IOW, could I risk to be blocked forever if that queue didn’t run right away.<br></p><p>That’s the problem to keep in mind with overcommit, it’s the intent. I don’t think the current wq implementation on OS X is pretty smart about it, probably not as much as it should.<br></p><p>As long as you fix that issue (guarantee that overcommit queue provided you don’t have 109238192038 competing for your cores will get a thread in a relatively timely fashion) then I think it’s ok if specific platforms semantics vary a bit. It’s already the case with the pthread thread pool vs wq anyway.<br></p><p>&gt;&gt; If your thread block in read() then I would argue that it should use a READ dispatch source instead, that way, the source would get enqueued *after* your async and you can ping pong. Doing blocking read()s is not dispatchy at all and will cause you all sorts of problems like that one, because re-async doesn’t work for you.<br>&gt; <br>&gt; Here we are a bit living with legacy considerations, but perhaps one possible way we are discussing is if such threads could use the pwq API (at the tail end) to facilitate the behavior you suggest.<br>&gt; <br>&gt; I.e. pseudocode:<br>&gt; <br>&gt; f() // legacy non-dispatchy code<br>&gt; {<br>&gt;  read()                                  // get some new work<br>&gt;  dispatch_async()                        // dispatch the work on a non-overcommit queue<br>&gt;  pthread_workqueue_additem_np(q, f, ...) // repeat f(), switch between overcommit/nonovercommit target work queues as needed/desired, this thread could thus be stolen to process the above dispatch_async<br>&gt; }<br></p><p>oh you’re not on a dispatchy thread, then yeah well, you’re more or less on your own. I would if you need that tweak the thread pool so that it always has one ready for you (IOW it never kills them all) so that the wake up is less expensive. But that’s clearly not a pattern we will try to optimize for because it’ll have bad effect on the library API surface for something that we prefer people try to embrace fully with time.<br></p><p>Here if you’re simulating dispatch this way though, you could have a source for the read still:<br></p><p>source = dispatch_source_create(DISPATCH_SOURCE_TYPE_READ, fd, NULL);<br>dispatch_source_set_event_handler_f(source, …, f);<br>dispatch_resume(source);<br></p><p>If your code really looks like you’re describing that should naturally work, no?<br></p><p><br></p><p>-Pierre<br></p></div></li></ul></li></ul></li></ul></li></ul></li></ul></li><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/27423842cafa2fc08bf56ff675a852e5?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Daniel A. Steffen</string> &lt;das at apple.com&gt;<p>December  7, 2015 at 02:00:00pm</p></header><div class="content"><p>Hi Joakim,<br></p><p>&gt; On Dec 7, 2015, at 4:55, Joakim Hassila via swift-corelibs-dev &lt;swift-corelibs-dev at swift.org&gt; wrote:<br>&gt; <br>&gt; Hi,<br>&gt; <br>&gt; I think (and hope) that this is the proper forum for a few questions wrt to libdispatch, otherwise any pointers are appreciated.<br>&gt; <br>&gt; We are currently using libdispatch extensively on Linux (and Solaris for a while longer…) based on the previous version available from Mac OS forge (with later additions merged from opensource.apple.com) over time.<br></p><p>FWIW I’ve updated the macosforge svn repo trunk to match with github swift-corelibs-libdispatch trunk (sans the PRs, excecpt for my buildsystem one), but going forward we are likely going to retire the macosforge repository in favor of the github one.<br></p><p>&gt; <br>&gt; I have a few questions on how (particularly Apple folks) view this going forward:<br>&gt; <br>&gt; First, the previous port to Linux/Solaris of libdispatch was dependent on libkqueue and more importantly on libpthread_workqueue (to have some heuristics for managing the number of threads when lacking kernel support).<br>&gt; <br>&gt; How do you view this, would you consider integrating support for libpthread_workqueue, or would you have another preference for how to manage this on other platforms (Linux for starters, but essentially any lacking the pthread_workqueue interface)?<br></p><p>yes, staying with libpthread_workqueue is the focus of the current Linux porting effort, but it may make sense to move to something more native over time, e.g. like on FreeBSD where a version of the kernel workqueue was implemented natively.<br></p><p>&gt; <br>&gt; Secondly, we have extended the public libdispatch API internally with one more flavor of dispatching, let’s call it ‘dispatch_async_inline’ - the semantics being ‘perform the processing of the work synchronously if we wouldn’t block the calling thread, if we would block, instead perform the work as a normal dispatch_async’.<br>&gt; <br>&gt; Would such a change be considered to be integrated, or should we keep our internal diffs indefinitely? Just to understand if it is worth the effort with a nicely packaged pull request or not...<br>&gt; <br>&gt; The rationale for the API is that we are quite latency sensitive and want to use inline processing up until the point where we can’t keep up with the available work, at which point we would switch to asynchronous processing seamlessly (we have multiple producers). This means that the thread calling this API can be stolen for a significant amount of time (emptying the queue it was assigned to), but when the system is under ‘light&#39; load, we don’t need to incur the wakeup penalty for a completely asynchronous dispatch.<br></p><p>sounds familiar, have we talked to about this in the past somewhere ?<br></p><p>we actually have something quite similar internal to the library already: _dispatch_barrier_trysync_f<br></p><p>	https://github.com/apple/swift-corelibs-libdispatch/blob/master/src/queue.c#L3089<br></p><p>but it currently (intentionally) ignores anything about the target queue hierarchy of the queue passed in (e.g. it will allow the sync even if the target queue is busy or suspended), so is not suitable as a general facility.<br></p><p>There are various technical reasons why we don’t believe this primitive in all generality is a good idea, Pierre is writing up an email about that so I won’t go into details here.<br></p><p>Daniel<br></p><p>&gt; <br>&gt; Cheers,<br>&gt; <br>&gt; Joakim<br>&gt; <br>&gt; PS Big kudos to whoever at Apple is responsible for driving fundamentals like this out as OSS…<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/8daa9d0c5cf56d891ee1e33571342032?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Joakim Hassila</string> &lt;Joakim.Hassila at orc-group.com&gt;<p>December  8, 2015 at 02:00:00pm</p></header><div class="content"><p>Hi Daniel,<br></p><p><br>&gt; On 7 dec. 2015, at 23:11, Daniel A. Steffen &lt;das at apple.com&gt; wrote:<br>&gt;<br>&gt; FWIW I’ve updated the macosforge svn repo trunk to match with github swift-corelibs-libdispatch trunk (sans the PRs, excecpt for my buildsystem one), but going forward we are likely going to retire the macosforge repository in favor of the github one.<br></p><p>That seems very reasonable and would make sense I think, there doesn’t seem to be much rationale for overlap.<br></p><p>&gt;<br>&gt;&gt;<br>&gt;&gt; I have a few questions on how (particularly Apple folks) view this going forward:<br>&gt;&gt;<br>&gt;&gt; First, the previous port to Linux/Solaris of libdispatch was dependent on libkqueue and more importantly on libpthread_workqueue (to have some heuristics for managing the number of threads when lacking kernel support).<br>&gt;&gt;<br>&gt;&gt; How do you view this, would you consider integrating support for libpthread_workqueue, or would you have another preference for how to manage this on other platforms (Linux for starters, but essentially any lacking the pthread_workqueue interface)?<br>&gt;<br>&gt; yes, staying with libpthread_workqueue is the focus of the current Linux porting effort, but it may make sense to move to something more native over time, e.g. like on FreeBSD where a version of the kernel workqueue was implemented natively.<br></p><p>Ok, that’s great - previously there was a discussion to actually integrate libpthread_workqueue at least directly into the libdispatch project to reduce the number of dependencies to get a reasonably working libdispatch running - currently Mark Heily put it up on GitHub as well at https://github.com/mheily/libpwq - it has been quite dormant for the last few years, but I think that is largely due to things working reasonably well.<br></p><p>So would such more close integration be desirable to make things build more out of the box, or would you prefer to only use it if found during build time on the current host? (I would probably prefer the first option, as it essentially just provides support for functionality that the underlying platform lacks - the current libpwq supports a few platforms…).<br></p><p>&gt; Secondly, we have extended the public libdispatch API internally with one more flavor of dispatching, let’s call it ‘dispatch_async_inline’ - the semantics being ‘perform the processing of the work synchronously if we wouldn’t block the calling thread, if we would block, instead perform the work as a normal dispatch_async’.<br>&gt;&gt;<br>&gt;&gt; Would such a change be considered to be integrated, or should we keep our internal diffs indefinitely? Just to understand if it is worth the effort with a nicely packaged pull request or not...<br>&gt;&gt;<br>&gt;&gt; The rationale for the API is that we are quite latency sensitive and want to use inline processing up until the point where we can’t keep up with the available work, at which point we would switch to asynchronous processing seamlessly (we have multiple producers). This means that the thread calling this API can be stolen for a significant amount of time (emptying the queue it was assigned to), but when the system is under ‘light&#39; load, we don’t need to incur the wakeup penalty for a completely asynchronous dispatch.<br>&gt;<br>&gt; sounds familiar, have we talked to about this in the past somewhere ?<br></p><p>Well, it could well be that we touched upon it on the old libdispatch mailing list a few years ago (I did change my surname from Johansson -&gt; Hassila as well as the company mail address, so it might have thrown things off for you :-). I did primarily spend some time in helping clean things up for usage on Solaris at that time though.<br></p><p>&gt;<br>&gt; we actually have something quite similar internal to the library already: _dispatch_barrier_trysync_f<br>&gt;<br>&gt;       https://github.com/apple/swift-corelibs-libdispatch/blob/master/src/queue.c#L3089<br>&gt;<br>&gt; but it currently (intentionally) ignores anything about the target queue hierarchy of the queue passed in (e.g. it will allow the sync even if the target queue is busy or suspended), so is not suitable as a general facility.<br>&gt;<br>&gt; There are various technical reasons why we don’t believe this primitive in all generality is a good idea, Pierre is writing up an email about that so I won’t go into details here.<br></p><p>Thanks! I will reply to that separately.<br></p><p>Cheers,<br></p><p>Joakim<br></p><p><br>________________________________<br></p><p>This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/562c2299436b75df013fb428ddf90ce6?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Pierre Habouzit</string> &lt;pierre at habouzit.net&gt;<p>December  8, 2015 at 07:00:00am</p></header><div class="content"><p>&gt; On Dec 8, 2015, at 6:11 AM, Joakim Hassila via swift-corelibs-dev &lt;swift-corelibs-dev at swift.org&gt; wrote:<br>&gt; <br>&gt; Hi Daniel,<br>&gt; <br>&gt; <br>&gt;&gt; On 7 dec. 2015, at 23:11, Daniel A. Steffen &lt;das at apple.com&gt; wrote:<br>&gt;&gt; <br>&gt;&gt; FWIW I’ve updated the macosforge svn repo trunk to match with github swift-corelibs-libdispatch trunk (sans the PRs, excecpt for my buildsystem one), but going forward we are likely going to retire the macosforge repository in favor of the github one.<br>&gt; <br>&gt; That seems very reasonable and would make sense I think, there doesn’t seem to be much rationale for overlap.<br>&gt; <br>&gt;&gt; <br>&gt;&gt;&gt; <br>&gt;&gt;&gt; I have a few questions on how (particularly Apple folks) view this going forward:<br>&gt;&gt;&gt; <br>&gt;&gt;&gt; First, the previous port to Linux/Solaris of libdispatch was dependent on libkqueue and more importantly on libpthread_workqueue (to have some heuristics for managing the number of threads when lacking kernel support).<br>&gt;&gt;&gt; <br>&gt;&gt;&gt; How do you view this, would you consider integrating support for libpthread_workqueue, or would you have another preference for how to manage this on other platforms (Linux for starters, but essentially any lacking the pthread_workqueue interface)?<br>&gt;&gt; <br>&gt;&gt; yes, staying with libpthread_workqueue is the focus of the current Linux porting effort, but it may make sense to move to something more native over time, e.g. like on FreeBSD where a version of the kernel workqueue was implemented natively.<br>&gt; <br>&gt; Ok, that’s great - previously there was a discussion to actually integrate libpthread_workqueue at least directly into the libdispatch project to reduce the number of dependencies to get a reasonably working libdispatch running - currently Mark Heily put it up on GitHub as well at https://github.com/mheily/libpwq - it has been quite dormant for the last few years, but I think that is largely due to things working reasonably well.<br>&gt; <br>&gt; So would such more close integration be desirable to make things build more out of the box, or would you prefer to only use it if found during build time on the current host? (I would probably prefer the first option, as it essentially just provides support for functionality that the underlying platform lacks - the current libpwq supports a few platforms…).<br></p><p>Hi,<br></p><p>FWIW, this is my personal, let’s call it enlightened, opinion, based on my knowledge of dispatch and my past extensive system programming experience with Linux before I joined Apple.<br></p><p>I think that long term, the best way to maintain a Linux libdispatch port is to go away from the libkqueue that tries to emulate kqueue fully, where dispatch only needs a small subset of the surface of kqueue. Given how source.c is written today, this is not a very small undertaking, but eventually dispatch source map to epoll_ctl(EPOLLONESHOT) very very well.<br></p><p>Given our experience with the work queue subsystem in Darwin, I think that it would make sense to integrate both projects together, as work queue are not that useful if you don’t have dispatch with it, and having it separate gives you all the woes of a stable interface, which you don’t really care for in the first place. It’s probably much better to integrate it and not care about backward and forward compatibility and make it a private library of dispatch on linux. And to not be tied to a given interface at all.<br></p><p>I also think that having a minimal kernel support for thread pool management isn’t that hard to write as a kernel module, I had started to work on this a very long time ago, using the KVM scheduling hooks that let you know when a thread blocks and/or becomes runnable[1]. Threads would declare to that interface that they are work queue threads, and get load information that the thread pool can use to regulate. It’s old code, maybe (probably?) not the right way to do it, but that’s an example of things you can do if you move away from the contrived interface from what libpthread_workqueue exposes. My idea required a linux adjustment that I posted to the LKML at the time (http://lkml.iu.edu/hypermail/linux/kernel/1112.2/00235.html) not sure if it ever made it to mainline (looks like it didn’t).<br></p><p><br>[1] http://git.madism.org/?p=~madcoder/pwqr.git;a=blob;f=kernel/pwqr.c;h=6d822ea6bca40a2ba8de3965526f33b4a98b8649;hb=HEAD<br></p><p><br>-Pierre<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/8daa9d0c5cf56d891ee1e33571342032?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Joakim Hassila</string> &lt;Joakim.Hassila at orc-group.com&gt;<p>December 10, 2015 at 08:00:00am</p></header><div class="content"><p>Hi,<br></p><p>&gt; On 8 dec. 2015, at 16:56, Pierre Habouzit &lt;pierre at habouzit.net&gt; wrote:<br>&gt;<br>&gt; FWIW, this is my personal, let’s call it enlightened, opinion, based on my knowledge of dispatch and my past extensive system programming experience with Linux before I joined Apple.<br>&gt;<br>&gt; I think that long term, the best way to maintain a Linux libdispatch port is to go away from the libkqueue that tries to emulate kqueue fully, where dispatch only needs a small subset of the surface of kqueue. Given how source.c is written today, this is not a very small undertaking, but eventually dispatch source map to epoll_ctl(EPOLLONESHOT) very very well.<br></p><p>That makes sense, could simplify the implementation (and keep thing cleaner). Then the follow up question is of course how to split/manage source.c (as Daniel pointed out there is the merging issue).<br></p><p>&gt; Given our experience with the work queue subsystem in Darwin, I think that it would make sense to integrate both projects together, as work queue are not that useful if you don’t have dispatch with it, and having it separate gives you all the woes of a stable interface, which you don’t really care for in the first place. It’s probably much better to integrate it and not care about backward and forward compatibility and make it a private library of dispatch on linux. And to not be tied to a given interface at all.<br></p><p>Agree, I don’t see much use for pwq except in this support role, so there would be a large degree of freedom.<br></p><p>&gt; I also think that having a minimal kernel support for thread pool management isn’t that hard to write as a kernel module, I had started to work on this a very long time ago, using the KVM scheduling hooks that let you know when a thread blocks and/or becomes runnable[1]. Threads would declare to that interface that they are work queue threads, and get load information that the thread pool can use to regulate. It’s old code, maybe (probably?) not the right way to do it, but that’s an example of things you can do if you move away from the contrived interface from what libpthread_workqueue exposes. My idea required a linux adjustment that I posted to the LKML at the time (http://lkml.iu.edu/hypermail/linux/kernel/1112.2/00235.html) not sure if it ever made it to mainline (looks like it didn’t).<br>&gt;<br>&gt;<br>&gt; [1] http://git.madism.org/?p=~madcoder/pwqr.git;a=blob;f=kernel/pwqr.c;h=6d822ea6bca40a2ba8de3965526f33b4a98b8649;hb=HEAD<br></p><p>That would actually be very nice to be able to regulate on a system level just as on Darwin.<br></p><p>On a conceptual level, it would probably make sense to consider also non-work queue threads for regulation purposes (it is what is being done on the user level right now in pwq: simply doing thread introspection of /proc when needed) - then it plays more nicely in a mixed environment where there are legacy threads doing work.<br></p><p>Joakim<br></p><p><br>________________________________<br></p><p>This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/562c2299436b75df013fb428ddf90ce6?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Pierre Habouzit</string> &lt;pierre at habouzit.net&gt;<p>December 10, 2015 at 09:00:00am</p></header><div class="content"><p>-Pierre<br></p><p>&gt; On Dec 10, 2015, at 12:42 AM, Joakim Hassila via swift-corelibs-dev &lt;swift-corelibs-dev at swift.org&gt; wrote:<br>&gt; <br>&gt; Hi,<br>&gt; <br>&gt;&gt; On 8 dec. 2015, at 16:56, Pierre Habouzit &lt;pierre at habouzit.net&gt; wrote:<br>&gt;&gt; <br>&gt;&gt; FWIW, this is my personal, let’s call it enlightened, opinion, based on my knowledge of dispatch and my past extensive system programming experience with Linux before I joined Apple.<br>&gt;&gt; <br>&gt;&gt; I think that long term, the best way to maintain a Linux libdispatch port is to go away from the libkqueue that tries to emulate kqueue fully, where dispatch only needs a small subset of the surface of kqueue. Given how source.c is written today, this is not a very small undertaking, but eventually dispatch source map to epoll_ctl(EPOLLONESHOT) very very well.<br>&gt; <br>&gt; That makes sense, could simplify the implementation (and keep thing cleaner). Then the follow up question is of course how to split/manage source.c (as Daniel pointed out there is the merging issue).<br></p><p>we can decide when/if someone tries to tackle it. I humbly recognize that I have no great idea of how to do so.<br></p><p>&gt; <br>&gt;&gt; Given our experience with the work queue subsystem in Darwin, I think that it would make sense to integrate both projects together, as work queue are not that useful if you don’t have dispatch with it, and having it separate gives you all the woes of a stable interface, which you don’t really care for in the first place. It’s probably much better to integrate it and not care about backward and forward compatibility and make it a private library of dispatch on linux. And to not be tied to a given interface at all.<br>&gt; <br>&gt; Agree, I don’t see much use for pwq except in this support role, so there would be a large degree of freedom.<br>&gt; <br>&gt;&gt; I also think that having a minimal kernel support for thread pool management isn’t that hard to write as a kernel module, I had started to work on this a very long time ago, using the KVM scheduling hooks that let you know when a thread blocks and/or becomes runnable[1]. Threads would declare to that interface that they are work queue threads, and get load information that the thread pool can use to regulate. It’s old code, maybe (probably?) not the right way to do it, but that’s an example of things you can do if you move away from the contrived interface from what libpthread_workqueue exposes. My idea required a linux adjustment that I posted to the LKML at the time (http://lkml.iu.edu/hypermail/linux/kernel/1112.2/00235.html) not sure if it ever made it to mainline (looks like it didn’t).<br>&gt;&gt; <br>&gt;&gt; <br>&gt;&gt; [1] http://git.madism.org/?p=~madcoder/pwqr.git;a=blob;f=kernel/pwqr.c;h=6d822ea6bca40a2ba8de3965526f33b4a98b8649;hb=HEAD<br>&gt; <br>&gt; That would actually be very nice to be able to regulate on a system level just as on Darwin.<br>&gt; <br>&gt; On a conceptual level, it would probably make sense to consider also non-work queue threads for regulation purposes (it is what is being done on the user level right now in pwq: simply doing thread introspection of /proc when needed) - then it plays more nicely in a mixed environment where there are legacy threads doing work.<br>&gt; <br>&gt; Joakim<br>&gt; <br>&gt; <br>&gt; ________________________________<br>&gt; <br>&gt; This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br>&gt; _______________________________________________<br>&gt; swift-corelibs-dev mailing list<br>&gt; swift-corelibs-dev at swift.org<br>&gt; https://lists.swift.org/mailman/listinfo/swift-corelibs-dev<br></p></div></li></ul></li></ul></li><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/27423842cafa2fc08bf56ff675a852e5?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Daniel A. Steffen</string> &lt;das at apple.com&gt;<p>December  8, 2015 at 09:00:00am</p></header><div class="content"><p>&gt; On Dec 8, 2015, at 6:11, Joakim Hassila &lt;Joakim.Hassila at orc-group.com&gt; wrote:<br>&gt; <br>&gt; Hi Daniel,<br>&gt; <br>&gt; <br>&gt;&gt; On 7 dec. 2015, at 23:11, Daniel A. Steffen &lt;das at apple.com&gt; wrote:<br>&gt;&gt; <br>&gt;&gt; FWIW I’ve updated the macosforge svn repo trunk to match with github swift-corelibs-libdispatch trunk (sans the PRs, excecpt for my buildsystem one), but going forward we are likely going to retire the macosforge repository in favor of the github one.<br>&gt; <br>&gt; That seems very reasonable and would make sense I think, there doesn’t seem to be much rationale for overlap.<br>&gt; <br>&gt;&gt; <br>&gt;&gt;&gt; <br>&gt;&gt;&gt; I have a few questions on how (particularly Apple folks) view this going forward:<br>&gt;&gt;&gt; <br>&gt;&gt;&gt; First, the previous port to Linux/Solaris of libdispatch was dependent on libkqueue and more importantly on libpthread_workqueue (to have some heuristics for managing the number of threads when lacking kernel support).<br>&gt;&gt;&gt; <br>&gt;&gt;&gt; How do you view this, would you consider integrating support for libpthread_workqueue, or would you have another preference for how to manage this on other platforms (Linux for starters, but essentially any lacking the pthread_workqueue interface)?<br>&gt;&gt; <br>&gt;&gt; yes, staying with libpthread_workqueue is the focus of the current Linux porting effort, but it may make sense to move to something more native over time, e.g. like on FreeBSD where a version of the kernel workqueue was implemented natively.<br>&gt; <br>&gt; Ok, that’s great - previously there was a discussion to actually integrate libpthread_workqueue at least directly into the libdispatch project to reduce the number of dependencies to get a reasonably working libdispatch running - currently Mark Heily put it up on GitHub as well at https://github.com/mheily/libpwq - it has been quite dormant for the last few years, but I think that is largely due to things working reasonably well.<br>&gt; <br>&gt; So would such more close integration be desirable to make things build more out of the box, or would you prefer to only use it if found during build time on the current host? (I would probably prefer the first option, as it essentially just provides support for functionality that the underlying platform lacks - the current libpwq supports a few platforms…).<br></p><p>That seems like a good idea in principle, I agree that it makes good technical sense given libdispatch is presumably the only client of this library, but short term continuing to keep it separate will likely be easiest (for boring non-technical reasons)<br></p><p>In particular I’ll have to figure out what the situation would be with us continuing to take changes internally from the github repo after importing a whole contributed project into it (as opposed to incremental patches to the existing sourcebase), ideally I would really prefer to not significantly diverge from our internal repo to make that process as straightforward as possible (essentially a git merge…)<br></p><p><br>&gt; <br>&gt;&gt; Secondly, we have extended the public libdispatch API internally with one more flavor of dispatching, let’s call it ‘dispatch_async_inline’ - the semantics being ‘perform the processing of the work synchronously if we wouldn’t block the calling thread, if we would block, instead perform the work as a normal dispatch_async’.<br>&gt;&gt;&gt; <br>&gt;&gt;&gt; Would such a change be considered to be integrated, or should we keep our internal diffs indefinitely? Just to understand if it is worth the effort with a nicely packaged pull request or not...<br>&gt;&gt;&gt; <br>&gt;&gt;&gt; The rationale for the API is that we are quite latency sensitive and want to use inline processing up until the point where we can’t keep up with the available work, at which point we would switch to asynchronous processing seamlessly (we have multiple producers). This means that the thread calling this API can be stolen for a significant amount of time (emptying the queue it was assigned to), but when the system is under ‘light&#39; load, we don’t need to incur the wakeup penalty for a completely asynchronous dispatch.<br>&gt;&gt; <br>&gt;&gt; sounds familiar, have we talked to about this in the past somewhere ?<br>&gt; <br>&gt; Well, it could well be that we touched upon it on the old libdispatch mailing list a few years ago (I did change my surname from Johansson -&gt; Hassila as well as the company mail address, so it might have thrown things off for you :-). I did primarily spend some time in helping clean things up for usage on Solaris at that time though.<br>&gt; <br>&gt;&gt; <br>&gt;&gt; we actually have something quite similar internal to the library already: _dispatch_barrier_trysync_f<br>&gt;&gt; <br>&gt;&gt;      https://github.com/apple/swift-corelibs-libdispatch/blob/master/src/queue.c#L3089<br>&gt;&gt; <br>&gt;&gt; but it currently (intentionally) ignores anything about the target queue hierarchy of the queue passed in (e.g. it will allow the sync even if the target queue is busy or suspended), so is not suitable as a general facility.<br>&gt;&gt; <br>&gt;&gt; There are various technical reasons why we don’t believe this primitive in all generality is a good idea, Pierre is writing up an email about that so I won’t go into details here.<br>&gt; <br>&gt; Thanks! I will reply to that separately.<br>&gt; <br>&gt; Cheers,<br>&gt; <br>&gt; Joakim<br>&gt; <br>&gt; <br>&gt; ________________________________<br>&gt; <br>&gt; This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/562c2299436b75df013fb428ddf90ce6?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Pierre Habouzit</string> &lt;pierre at habouzit.net&gt;<p>December  8, 2015 at 09:00:00am</p></header><div class="content"><p>&gt; On Dec 8, 2015, at 9:05 AM, Daniel A. Steffen via swift-corelibs-dev &lt;swift-corelibs-dev at swift.org&gt; wrote:<br>&gt; <br>&gt;&gt; <br>&gt;&gt; On Dec 8, 2015, at 6:11, Joakim Hassila &lt;Joakim.Hassila at orc-group.com&gt; wrote:<br>&gt;&gt; <br>&gt;&gt; Hi Daniel,<br>&gt;&gt; <br>&gt;&gt; <br>&gt;&gt;&gt; On 7 dec. 2015, at 23:11, Daniel A. Steffen &lt;das at apple.com&gt; wrote:<br>&gt;&gt;&gt; <br>&gt;&gt;&gt; FWIW I’ve updated the macosforge svn repo trunk to match with github swift-corelibs-libdispatch trunk (sans the PRs, excecpt for my buildsystem one), but going forward we are likely going to retire the macosforge repository in favor of the github one.<br>&gt;&gt; <br>&gt;&gt; That seems very reasonable and would make sense I think, there doesn’t seem to be much rationale for overlap.<br>&gt;&gt; <br>&gt;&gt;&gt; <br>&gt;&gt;&gt;&gt; <br>&gt;&gt;&gt;&gt; I have a few questions on how (particularly Apple folks) view this going forward:<br>&gt;&gt;&gt;&gt; <br>&gt;&gt;&gt;&gt; First, the previous port to Linux/Solaris of libdispatch was dependent on libkqueue and more importantly on libpthread_workqueue (to have some heuristics for managing the number of threads when lacking kernel support).<br>&gt;&gt;&gt;&gt; <br>&gt;&gt;&gt;&gt; How do you view this, would you consider integrating support for libpthread_workqueue, or would you have another preference for how to manage this on other platforms (Linux for starters, but essentially any lacking the pthread_workqueue interface)?<br>&gt;&gt;&gt; <br>&gt;&gt;&gt; yes, staying with libpthread_workqueue is the focus of the current Linux porting effort, but it may make sense to move to something more native over time, e.g. like on FreeBSD where a version of the kernel workqueue was implemented natively.<br>&gt;&gt; <br>&gt;&gt; Ok, that’s great - previously there was a discussion to actually integrate libpthread_workqueue at least directly into the libdispatch project to reduce the number of dependencies to get a reasonably working libdispatch running - currently Mark Heily put it up on GitHub as well at https://github.com/mheily/libpwq - it has been quite dormant for the last few years, but I think that is largely due to things working reasonably well.<br>&gt;&gt; <br>&gt;&gt; So would such more close integration be desirable to make things build more out of the box, or would you prefer to only use it if found during build time on the current host? (I would probably prefer the first option, as it essentially just provides support for functionality that the underlying platform lacks - the current libpwq supports a few platforms…).<br>&gt; <br>&gt; That seems like a good idea in principle, I agree that it makes good technical sense given libdispatch is presumably the only client of this library, but short term continuing to keep it separate will likely be easiest (for boring non-technical reasons)<br>&gt; <br>&gt; In particular I’ll have to figure out what the situation would be with us continuing to take changes internally from the github repo after importing a whole contributed project into it (as opposed to incremental patches to the existing sourcebase), ideally I would really prefer to not significantly diverge from our internal repo to make that process as straightforward as possible (essentially a git merge…)<br></p><p>That is a good point.<br></p><p>Merging the codebases doesn’t necessarily require that they live in the same source repository though. I’m just arguing that if the worqueue code/emulation/layer is meant to only have dispatch as a client it allows for something more flexible.<br></p><p>-Pierre<br></p></div></li><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/8daa9d0c5cf56d891ee1e33571342032?s=50"></div><header><strong>libdispatch roadmap and api addition proposal</strong> from <string>Joakim Hassila</string> &lt;Joakim.Hassila at orc-group.com&gt;<p>December 10, 2015 at 08:00:00am</p></header><div class="content"><p>On 8 dec. 2015, at 18:05, Daniel A. Steffen &lt;das at apple.com&gt; wrote:<br>&gt;<br>&gt;<br>&gt;&gt; On Dec 8, 2015, at 6:11, Joakim Hassila &lt;Joakim.Hassila at orc-group.com&gt; wrote:<br>&gt;&gt;<br>&gt;&gt;<br>&gt;&gt; Ok, that’s great - previously there was a discussion to actually integrate libpthread_workqueue at least directly into the libdispatch project to reduce the number of dependencies to get a reasonably working libdispatch running - currently Mark Heily put it up on GitHub as well at https://github.com/mheily/libpwq - it has been quite dormant for the last few years, but I think that is largely due to things working reasonably well.<br>&gt;&gt;<br>&gt;&gt; So would such more close integration be desirable to make things build more out of the box, or would you prefer to only use it if found during build time on the current host? (I would probably prefer the first option, as it essentially just provides support for functionality that the underlying platform lacks - the current libpwq supports a few platforms…).<br>&gt;<br>&gt; That seems like a good idea in principle, I agree that it makes good technical sense given libdispatch is presumably the only client of this library, but short term continuing to keep it separate will likely be easiest (for boring non-technical reasons)<br></p><p>Ok.<br></p><p>&gt; In particular I’ll have to figure out what the situation would be with us continuing to take changes internally from the github repo after importing a whole contributed project into it (as opposed to incremental patches to the existing sourcebase), ideally I would really prefer to not significantly diverge from our internal repo to make that process as straightforward as possible (essentially a git merge…)<br></p><p>Right - would perhaps be good to try to have some guidelines on how such integration should be done in general (hopefully support for additional platforms will be added over time, so it would be good to have a systematic approach to how to do the platform specific changes without breaking your merge process completely - I think that is in everyones interest). Would you make a suggestion on what would work well in practice later for long-term?<br></p><p>Out of curiosity on a more philosophical note - do you view the libdipsatch internal repo or the GitHub one to be ‘upstream’? In the Ars interview, Craig Federighi said &quot;The Swift team will be developing completely in the open on GitHub” which implied the GitHub version being the ‘upstream’ one - how you view that for libdispatch would possibly impact the ‘divergence’ aspect… I understand the answer can well be different for various reasons...<br></p><p>Cheers,<br></p><p>Joakim<br></p><p><br></p><p><br>________________________________<br></p><p>This e-mail is confidential and may contain legally privileged information. It is intended only for the addressees. If you have received this e-mail in error, kindly notify us immediately by telephone or e-mail and delete the message from your system.<br></p></div></li></ul></li></ul></li></ul></li></ul></li></ul></div>    </main>
    <script src="/js/app-c283ee129de63ad743722e9511e67a5d.js"></script>
  </body>
  <footer>
    <p>Swift and the Swift logo are trademarks of Apple Inc.</p>
  </footer>
</html>
