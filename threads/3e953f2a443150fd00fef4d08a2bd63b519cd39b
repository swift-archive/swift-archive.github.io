<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Swift Mailing List Archive</title>
    <link rel="stylesheet" href="/css/app-13f065ae5e595562a5022c544e3b976c.css?vsn=d">
  </head>

  <body>
    <div class="container">
      <header class="header">
        <img src="/images/swift-d0237fc716ba0932a940049990beba1b.svg?vsn=d" height="70">
      </header>

      <p class="alert alert-info" role="alert"></p>
      <p class="alert alert-danger" role="alert"></p>

    </div> <!-- /container -->
    <main role="main">
<div class="comment-wrapper"><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/b9904260218b6d7942782c2b2355f2aa?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>William Dillon</string> &lt;william at housedillon.com&gt;<p>March  2, 2016 at 09:00:00am</p></header><div class="content"><p>Please see the gist for the most up-to-date drafts.<br></p><p>I appreciate any comments, concerns and questions!<br></p><p>Improve the portability of Swift with differently signed char.<br></p><p>Proposal: SE–004x<br>Author: William Dillon<br>Status: Draft<br>Review manager: TBD<br>Introduction<br></p><p>In C, the signness of char is undefined. A convention is set by either the platform, such as Windows, or by the architecture ABI specification, as is typical on System-V derived systems. A subset of known platforms germane to this discussion and their char signness is provided below.<br></p><p>char	ARM	mips	PPC	PPC64	i386	x86_64<br>Linux/ELF	unsigned 1	unsigned 2	unsigned 3	unsigned 4	signed 5	signed 6<br>Mach-O	signed [7]	N/A	signed [7]	signed [7]	signed [7]	signed [7]<br>Windows	signed [8]	signed [8]	signed [8]	signed [8]	signed [8]	signed [8]<br>This is not a great problem in C, and indeed many aren’t even aware of the issue. Part of the reason for this is that C will silently cast many types into other similar types as necessary. Notably, even with -Wall clang produces no warnings while casting beteen any pair of char, unsigned char, signed char and int. Swift, in contrast, does not cast types without explicit direction from the programmer. As implemented, char is interpreted by swift as Int8, regardless of whether the underlying platform uses signed or unsigned char. As every Apple platform (seemingly) uses signed char as a convention, it was an appropriate choice. However, now that Swift is being ported to more and more platforms, it is important that we decide how to handle the alternate case.<br></p><p>The problem at hand may be most simply demonstrated by a small example. Consider a C API where a set of functions return values as char:<br></p><p>char charNegFunction(void)    { return  -1; }<br>char charBigPosFunction(void) { return 255; }<br>char charPosFunction(void)    { return   1; }<br>Then, if the API is used in C thusly: C char negValue = charNegFunction(); char posValue = charPosFunction(); char bigValue = charBigPosFunction(); printf(&quot;From clang: Negative value: %d, positive value: %d, big positive value: %d\n&quot;, negValue, posValue, bigValue); You get exactly what you would expect on signed char platforms: From clang: Negative value: -1, positive value: 1, big positive value: -1 and on unsigned char platforms: From clang: Negative value: 255, positive value: 1, big positive value: 255 In its current state, swift behaves similarly to C on signed char platforms. From Swift: Negative value: -1, positive value: 1, big positive value: -1<br></p><p>This code is available here, if you would like to play with it yourself.<br></p><p>Motivation<br></p><p>The third stated focus area for Swift 3.0 is portability, to quote the evolution document:<br></p><p>Portability: Make Swift available on other platforms and ensure that one can write portable Swift code that works properly on all of those platforms.<br>As it stands, Swift’s indifference to the signness of char while importing from C can be ignored in many cases. The consequences of inaction, however, leave the door open for extremely subtle and dificult to diagnose bugs any time a C API relies on the use of values greater than 128 on platforms with unsigned char; in this case the current import model certainly violates the Principle of Least Astonishment.<br></p><p>This is not an abstract problem that I want to have solved “just because.” This issue has been a recurrent theme, and has come up several times during code review. I’ve included a sampling of these to provide some context to the discussion:<br></p><p>Swift PR–1103<br>Swift Foundation PR–265<br>In these discussions we obviously struggle to adequately solve the issues at hand without introducing the changes proposed here. Indeed, this proposal was suggested in Swift Foundation PR–265 by Joe Groff.<br></p><p>These changes should happen during a major release. Considering them for Swift 3 will enable us to move forward efficiently while constraining any source incompatibilities to transitions where users expect them. Code that works properly on each of these platforms is already likely to work properly. Further, the implementation of this proposal will identify cases where a problem exists and the symptoms have not yet been identified.<br></p><p>Proposed solution<br></p><p>I propose that the CChar be aliased to UInt8 on targets where char is unsigned, and Int8 on platforms where char is signed.<br></p><p>Detailed design<br></p><p>In principle this is a very small change to swift/stdlib/public/core/CTypes.swift:<br></p><p> ///<br> /// This will be the same as either `CSignedChar` (in the common<br> /// case) or `CUnsignedChar`, depending on the platform.<br>+#if os(OSX) || os(iOS) || os(windows) || arch(i383) || arch(x86_64)<br> public typealias CChar = Int8<br>+#else<br>+public typealias CChar = UInt8<br>+#endif<br>Impact on existing code<br></p><p>Though the change itself is trivial, the impact on other parts of the project including stdlib and foundation cannot be be ignored. To get a handle on the scope of the required changes, I’ve performed this change on the swift project, and I encourage any interested party to invesigate. https://github.com/apple/swift/compare/master…hpux735:char This project fork builds on both signed and unsigned char platforms. There is one test failure on signed char platforms and two test failures on unsigned char platforms resulting from remaining assumptions about the signness of char. They should be trivial to address by someone skilled at lit tests, and will be fixed prior to any pull request.<br></p><p>In general, code that you write will fail to compile if you assume that C APIs will continue to import char as Int8. Your choice is to write code that interfaces with char using CChar or to break it out into seperate cases. Other than one test, which relies on breaking the char assumption for the purposes of generating an error, I have not seen a case that justifies using conditional compilation directives over CChar. There are cases where it is necessary to cast to a concretely-signed type, such as UInt8 or Int8 from CChar, but in those cases it encourages you to consider the impact of assuming the structure of the data that you’re working with. Very often, if you write your code using CChar it will be portable, and compile cleanly on all platforms.<br></p><p>Alternatives considered<br></p><p>The only real alternative is the status quo. Currently, Swift treats all unspecified chars as signed. This mostly works most of the time, but I think we can do better.<br></p><p>Footnotes<br></p><p>[7]: proof by construction (is it signed by convention?) ``` $ cat test.c char char(char a) { return a; } signed char schar(signed char a) { return a; } unsigned char _uchar(unsigned char a) { return a; }<br></p><p>$ clang -S -emit-llvm -target -unknown-{windows,darwin} ``` and look for “signext” OR “zeroext&quot; in @_char definition<br></p><p>[8]: Windows char is signed by convention.<br>-------------- next part --------------<br>An HTML attachment was scrubbed...<br>URL: &lt;https://lists.swift.org/pipermail/swift-evolution/attachments/20160302/3e95d39b/attachment.html&gt;<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/969b04d28c02f951ccc03f615b9a92b3?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>Dmitri Gribenko</string> &lt;gribozavr at gmail.com&gt;<p>March  2, 2016 at 10:00:00am</p></header><div class="content"><p>On Wed, Mar 2, 2016 at 9:56 AM, William Dillon via swift-evolution &lt;<br>swift-evolution at swift.org&gt; wrote:<br></p><p>&gt; Please see the gist &lt;https://gist.github.com/hpux735/eafad78108ed42879690&gt;<br>&gt; for the most up-to-date drafts.<br>&gt;<br>&gt; I appreciate any comments, concerns and questions!<br>&gt; Improve the portability of Swift with differently signed char.<br>&gt;<br>&gt;    - Proposal: SE–004x<br>&gt;    &lt;https://github.com/apple/swift-evolution/blob/master/proposals/004x-target-specific-chars.md&gt;<br>&gt;    - Author: William Dillon &lt;https://github.com/hpux735&gt;<br>&gt;    - Status: *Draft*<br>&gt;    - Review manager: TBD<br>&gt;<br>&gt; Introduction<br>&gt;<br>&gt; In C, the signness of char is undefined. A convention is set by either<br>&gt; the platform, such as Windows, or by the architecture ABI specification, as<br>&gt; is typical on System-V derived systems. A subset of known platforms germane<br>&gt; to this discussion and their char signness is provided below.<br>&gt; char ARM mips PPC PPC64 i386 x86_64<br>&gt; Linux/ELF unsigned 1<br>&gt; &lt;http://www.eecs.umich.edu/courses/eecs373/readings/ARM-AAPCS-EABI-v2.08.pdf&gt; unsigned<br>&gt; 2 &lt;http://math-atlas.sourceforge.net/devel/assembly/mipsabi32.pdf&gt; unsigned<br>&gt; 3 &lt;https://uclibc.org/docs/psABI-ppc.pdf&gt; unsigned 4<br>&gt; &lt;http://refspecs.linuxfoundation.org/ELF/ppc64/PPC-elf64abi.html&gt; signed 5<br>&gt; &lt;http://www.sco.com/developers/devspecs/abi386-4.pdf&gt; signed 6<br>&gt; &lt;http://www.x86-64.org/documentation/abi.pdf&gt;<br>&gt; Mach-O signed [7] N/A signed [7] signed [7] signed [7] signed [7]<br>&gt; Windows signed [8] signed [8] signed [8] signed [8] signed [8] signed [8]<br>&gt;<br>&gt; This is not a great problem in C, and indeed many aren’t even aware of the<br>&gt; issue. Part of the reason for this is that C will silently cast many types<br>&gt; into other similar types as necessary. Notably, even with -Wall clang<br>&gt; produces no warnings while casting beteen any pair of char, unsigned char,<br>&gt; signed char and int. Swift, in contrast, does not cast types without<br>&gt; explicit direction from the programmer. As implemented, char is<br>&gt; interpreted by swift as Int8, regardless of whether the underlying<br>&gt; platform uses signed or unsigned char. As every Apple platform<br>&gt; (seemingly) uses signed char as a convention, it was an appropriate<br>&gt; choice. However, now that Swift is being ported to more and more platforms,<br>&gt; it is important that we decide how to handle the alternate case.<br>&gt;<br>&gt; The problem at hand may be most simply demonstrated by a small example.<br>&gt; Consider a C API where a set of functions return values as char:<br>&gt;<br>&gt; char charNegFunction(void)    { return  -1; }<br>&gt; char charBigPosFunction(void) { return 255; }<br>&gt; char charPosFunction(void)    { return   1; }<br>&gt;<br>&gt; Then, if the API is used in C thusly: C char negValue =<br>&gt; charNegFunction(); char posValue = charPosFunction(); char bigValue =<br>&gt; charBigPosFunction(); printf(&quot;From clang: Negative value: %d, positive<br>&gt; value: %d, big positive value: %d\n&quot;, negValue, posValue, bigValue); You<br>&gt; get exactly what you would expect on signed char platforms: From clang:<br>&gt; Negative value: -1, positive value: 1, big positive value: -1 and on unsigned<br>&gt; char platforms: From clang: Negative value: 255, positive value: 1, big<br>&gt; positive value: 255 In its current state, swift behaves similarly to C on signed<br>&gt; char platforms. From Swift: Negative value: -1, positive value: 1, big<br>&gt; positive value: -1<br>&gt;<br>&gt; This code is available here &lt;https://github.com/hpux735/badCharExample&gt;,<br>&gt; if you would like to play with it yourself.<br>&gt; Motivation<br>&gt;<br>&gt; The third stated focus area for Swift 3.0 is *portability*, to quote the<br>&gt; evolution document:<br>&gt;<br>&gt;<br>&gt;    - *Portability*: Make Swift available on other platforms and ensure<br>&gt;    that one can write portable Swift code that works properly on all of those<br>&gt;    platforms.<br>&gt;<br>&gt; As it stands, Swift’s indifference to the signness of char while<br>&gt; importing from C can be ignored in many cases. The consequences of<br>&gt; inaction, however, leave the door open for extremely subtle and dificult to<br>&gt; diagnose bugs any time a C API relies on the use of values greater than 128<br>&gt; on platforms with unsigned char; in this case the current import model<br>&gt; certainly violates the Principle of Least Astonishment.<br>&gt;<br></p><p>It does violate the principle of least astonishment, but we should<br>acknowledge that the implementation-specific nature of C&#39;s char signedness<br>is making code *less* portable, not more -- because the same code can mean<br>different things on different platforms.  Reflecting the same in Swift<br>makes Swift code less portable, too.<br></p><p>Dmitri<br></p><p>-- <br>main(i,j){for(i=2;;i++){for(j=2;j&lt;i;j++){if(!(i%j)){j=0;break;}}if<br>(j){printf(&quot;%d\n&quot;,i);}}} /*Dmitri Gribenko &lt;gribozavr at gmail.com&gt;*/<br>-------------- next part --------------<br>An HTML attachment was scrubbed...<br>URL: &lt;https://lists.swift.org/pipermail/swift-evolution/attachments/20160302/ea7b0053/attachment.html&gt;<br></p></div></li><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/be09ed656d5d90501c958b001261f218?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>Jeremy Pereira</string> &lt;jeremy.j.pereira at googlemail.com&gt;<p>March  3, 2016 at 10:00:00am</p></header><div class="content"><p>&gt; On 2 Mar 2016, at 18:56, William Dillon via swift-evolution &lt;swift-evolution at swift.org&gt; wrote:<br>&gt; <br>&gt; <br>&gt; <br>&gt; I propose that the CChar be aliased to UInt8 on targets where char is unsigned, and Int8 on platforms where char is signed.<br></p><p>This will make Swift code _less_ portable, since you will have to write different Swift code depending on whether your C implementation of char is signed or unsigned.<br></p><p><br>&gt; <br>&gt; Alternatives considered<br>&gt; <br>&gt; The only real alternative is the status quo.<br></p><p>No it isn’t. As long as CChar remains an alias to one of the integer types, it would be better to make it an alias to UInt8. The reason being that char * is often a pointer to a sequence of UTF-8 bytes and this interpretation is only going to get more common. String.UTF8View consists of a sequence of CodeUnits and UTF8.CodeUnit is, itself an alias to UInt8. <br></p><p>As others have said, it might be even better to have a new opaque type that’s 8 bits wide (I assume we are ignoring the fact that the C standard doesn’t define the width of a byte) but, in that case, I would argue that bitwise operations should be allowed on it.<br></p><p>&gt; Currently, Swift treats all unspecified chars as signed. This mostly works most of the time, but I think we can do better.<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/b9904260218b6d7942782c2b2355f2aa?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>William Dillon</string> &lt;william at housedillon.com&gt;<p>March  3, 2016 at 10:00:00am</p></header><div class="content"><p>&gt;&gt; I propose that the CChar be aliased to UInt8 on targets where char is unsigned, and Int8 on platforms where char is signed.<br>&gt; <br>&gt; This will make Swift code _less_ portable, since you will have to write different Swift code depending on whether your C implementation of char is signed or unsigned.<br>&gt; <br></p><p>I’m not sure I agree in general, but I can see why you think that way.<br></p><p>&gt; <br>&gt;&gt; <br>&gt;&gt; Alternatives considered<br>&gt;&gt; <br>&gt;&gt; The only real alternative is the status quo.<br>&gt; <br>&gt; No it isn’t. As long as CChar remains an alias to one of the integer types, it would be better to make it an alias to UInt8. The reason being that char * is often a pointer to a sequence of UTF-8 bytes and this interpretation is only going to get more common. String.UTF8View consists of a sequence of CodeUnits and UTF8.CodeUnit is, itself an alias to UInt8. <br>&gt; <br>&gt; As others have said, it might be even better to have a new opaque type that’s 8 bits wide (I assume we are ignoring the fact that the C standard doesn’t define the width of a byte) but, in that case, I would argue that bitwise operations should be allowed on it.<br>&gt; <br></p><p>I had a similar thought about bitwise operators.  Please see the updated gist:<br></p><p>https://gist.github.com/hpux735/eafad78108ed42879690<br></p><p>- Will<br></p></div></li></ul></li><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/bdd257c9369fb68e1d06923d10ff789e?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>Ben Rimmington</string> &lt;me at benrimmington.com&gt;<p>March  3, 2016 at 12:00:00pm</p></header><div class="content"><p>Apart from `CChar`, are the other typealiases in &quot;CTypes.swift&quot; also not portable?<br></p><p>For example, `CLong` and `CUnsignedLong` with LLP64 platforms (e.g. Microsoft Windows)?<br></p><p>Should the Clang Importer use the same typealiases in generated interfaces, to encourage portability?<br></p><p>&gt; - public func labs(_: Int) -&gt; Int<br>&gt; + public func labs(_: CLong) -&gt; CLong<br></p><p>-- Ben<br></p></div></li><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/bdd257c9369fb68e1d06923d10ff789e?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>Ben Rimmington</string> &lt;me at benrimmington.com&gt;<p>March  4, 2016 at 02:00:00am</p></header><div class="content"><p>Related bugs:<br></p><p>[SR-466] Imported APIs taking chars should use CChar<br>&lt;https://bugs.swift.org/browse/SR-466&gt;<br></p><p>[SR-747] CChar(&quot;\n&quot;) returns nil<br>&lt;https://bugs.swift.org/browse/SR-747&gt;<br></p><p>-- Ben<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/b9904260218b6d7942782c2b2355f2aa?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>William Dillon</string> &lt;william at housedillon.com&gt;<p>March  3, 2016 at 06:00:00pm</p></header><div class="content"><p>Thanks so much, Ben!<br></p><p>I’ve added them to the gist: https://gist.github.com/hpux735/eafad78108ed42879690<br></p><p>- Will<br></p><p>&gt; On Mar 3, 2016, at 6:38 PM, Ben Rimmington &lt;me at benrimmington.com&gt; wrote:<br>&gt; <br>&gt; Related bugs:<br>&gt; <br>&gt; [SR-466] Imported APIs taking chars should use CChar<br>&gt; &lt;https://bugs.swift.org/browse/SR-466&gt;<br>&gt; <br>&gt; [SR-747] CChar(&quot;\n&quot;) returns nil<br>&gt; &lt;https://bugs.swift.org/browse/SR-747&gt;<br>&gt; <br>&gt; -- Ben<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/b9904260218b6d7942782c2b2355f2aa?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>William Dillon</string> &lt;william at housedillon.com&gt;<p>March  4, 2016 at 04:00:00pm</p></header><div class="content"><p>Hi All,<br></p><p>I’ve been exploring the idea of importing C chars as RawByte (and type aliasing RawByte to CChar) in my prototype branch of Swift, and I would appreciate some insight from the hive mind.  Specifically, I’m interested in opinions about where to “draw the line” regarding C strings.<br></p><p>Currently (in the master branch) it’s easy convert between NSString, String and C-strings (often represented somewhat inconsistently by [CChar] or [(U)Int8], or UnsafePointer&lt;CChar&gt;).  If we are interested in importing C char as RawByte, we have to decide where C strings become UTF8 (i.e. UInt8).  I feel most comfortable drawing this line as close to C as possible, but I could see that there would be a reason for leaving it as CChar until it becomes proper UTF8.<br></p><p>If every reference to “Cstring” (for example: public init?(CString: UnsafePointer&lt;CChar&gt;…) is done with CChar, there can be a clean break, and an obvious place where Swift’s String handling begins, and C string handling ends.  It may discourage people from trying to do string processing outside of the context of unicode (kinda).  It would still be possible for people to work with characters in a C-string, however, as CChar will have a small number of operators defined over it, and you could always cast it to UInt8 or Int8.<br></p><p>I hope that this email opens up the discussion, and we can come up with a good idea that works for most people.  I’m kinda spinning because I don’t have a firm idea of the trade-offs for each solution.  Any consensus here would certainly help me finish the prototype.<br></p><p>Thanks!<br>- Will<br></p></div></li></ul></li></ul></li><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/283bdc6ec76dd4d16b7a8234222e55d4?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>Michel Fortin</string> &lt;michel.fortin at michelf.ca&gt;<p>March  4, 2016 at 08:00:00pm</p></header><div class="content"><p>&gt; As it stands, Swift’s indifference to the signness of char while importing from C can be ignored in many cases. The consequences of inaction, however, leave the door open for extremely subtle and dificult to diagnose bugs any time a C API relies on the use of values greater than 128 on platforms with unsigned char; in this case the current import model certainly violates the Principle of Least Astonishment.<br>&gt; <br>&gt; This is not an abstract problem that I want to have solved “just because.” This issue has been a recurrent theme, and has come up several times during code review. I’ve included a sampling of these to provide some context to the discussion:<br>&gt; <br>&gt; 	• Swift PR–1103<br>&gt; 	• Swift Foundation PR–265<br>&gt; In these discussions we obviously struggle to adequately solve the issues at hand without introducing the changes proposed here. Indeed, this proposal was suggested in Swift Foundation PR–265 by Joe Groff<br></p><p>I don&#39;t want to downplay the issue, but I also wouldn&#39;t want the remedy to be worse than the problem it tries to solve.<br></p><p>One remedy is to have char map to Int8 or UInt8 depending on the platform, but this introduces C portability issues in Swift itself so it&#39;s not very good.<br></p><p>Another remedy is to have an &quot;opaque&quot; CChar type that you have to cast to Int8 or UInt8 manually. While this removes the portability issue, it introduces friction in Swift whenever you need to use a C API that uses char. It also introduces a risk that the manual conversion is done wrong.<br></p><p>Given the distribution of platforms using an unsigned char by default, I do wonder if there are libraries out there that actually depend on that. It seems to me that any C code depending on an unsigned char by default is already at risk of silently producing wrong results just by moving to a different CPU. In most circumstances, that&#39;d be considered a bug in the C code.<br></p><p>So, my question is: are we contemplating complicating the language and introducing friction for everyone only for a theoretical interoperability problem that would never happen in practice? I would suggest that perhaps the best remedy for this would be to just translate char to Int8 all the time, including on those platforms-architecture combos where it goes against the default C behavior. Just document somewhere that it is so, perhaps offer a flag so you can reverse the importer&#39;s behavior in some circumstances, and be done with it.<br></p><p>-- <br>Michel Fortin<br>https://michelf.ca<br></p></div><ul class="comments"><li class="comment"><div class="avatar"><img src="https://www.gravatar.com/avatar/b9904260218b6d7942782c2b2355f2aa?s=50"></div><header><strong>[Draft] Target-specific CChar</strong> from <string>William Dillon</string> &lt;william at housedillon.com&gt;<p>March  7, 2016 at 08:00:00am</p></header><div class="content"><p>&gt; On Mar 4, 2016, at 5:52 PM, Michel Fortin &lt;michel.fortin at michelf.ca&gt; wrote:<br>&gt; <br>&gt;&gt; As it stands, Swift’s indifference to the signness of char while importing from C can be ignored in many cases. The consequences of inaction, however, leave the door open for extremely subtle and dificult to diagnose bugs any time a C API relies on the use of values greater than 128 on platforms with unsigned char; in this case the current import model certainly violates the Principle of Least Astonishment.<br>&gt;&gt; <br>&gt;&gt; This is not an abstract problem that I want to have solved “just because.” This issue has been a recurrent theme, and has come up several times during code review. I’ve included a sampling of these to provide some context to the discussion:<br>&gt;&gt; <br>&gt;&gt; 	• Swift PR–1103<br>&gt;&gt; 	• Swift Foundation PR–265<br>&gt;&gt; In these discussions we obviously struggle to adequately solve the issues at hand without introducing the changes proposed here. Indeed, this proposal was suggested in Swift Foundation PR–265 by Joe Groff<br>&gt; <br>&gt; I don&#39;t want to downplay the issue, but I also wouldn&#39;t want the remedy to be worse than the problem it tries to solve.<br>&gt; <br></p><p>Believe me when I say that any solution that is worse than the current state would be unacceptable to me.<br></p><p>&gt; One remedy is to have char map to Int8 or UInt8 depending on the platform, but this introduces C portability issues in Swift itself so it&#39;s not very good.<br>&gt; <br>&gt; Another remedy is to have an &quot;opaque&quot; CChar type that you have to cast to Int8 or UInt8 manually. While this removes the portability issue, it introduces friction in Swift whenever you need to use a C API that uses char. It also introduces a risk that the manual conversion is done wrong.<br>&gt; <br></p><p>I’ve updated the Gist; the second remedy that you mentioned is the current preferred solution.  It’s true that the manual conversion could be done wrong, but please remember that the conversion is happening currently, it’s just done for you by Swift.  The possibility of inappropriate conversion is still very real, but the user has no control over it.<br></p><p>&gt; Given the distribution of platforms using an unsigned char by default, I do wonder if there are libraries out there that actually depend on that. It seems to me that any C code depending on an unsigned char by default is already at risk of silently producing wrong results just by moving to a different CPU. In most circumstances, that&#39;d be considered a bug in the C code.<br>&gt; <br></p><p>That is not an unreasonable position.<br></p><p>&gt; So, my question is: are we contemplating complicating the language and introducing friction for everyone only for a theoretical interoperability problem that would never happen in practice? I would suggest that perhaps the best remedy for this would be to just translate char to Int8 all the time, including on those platforms-architecture combos where it goes against the default C behavior. Just document somewhere that it is so, perhaps offer a flag so you can reverse the importer&#39;s behavior in some circumstances, and be done with it.<br>&gt; <br></p><p>Again, my intention is to not introduce undue friction.  I’ve ported the standard library (and some of Foundation) for each of the candidate solutions, and the changes are extremely minor.  In fact, in the vast majority of cases, it is enough to simply select the correct type when designing the method signatures and variables.<br></p><p>Thanks for taking the time to share your thoughts.<br>- Will<br></p></div></li></ul></li></ul></li></ul></div>    </main>
    <script src="/js/app-c283ee129de63ad743722e9511e67a5d.js?vsn=d"></script>
  </body>
  <footer>
    <p>Swift and the Swift logo are trademarks of Apple Inc.</p>
  </footer>
</html>
